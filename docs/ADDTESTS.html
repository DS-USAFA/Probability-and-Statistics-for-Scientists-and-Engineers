<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 20 Additional Hypothesis Tests | Probability and Statistics for Scientists and Engineers</title>
<meta name="author" content="Matthew Davis">
<meta name="author" content="Brianna Hitt">
<meta name="author" content="Ken Horton">
<meta name="author" content="Kris Pruitt">
<meta name="author" content="Bradley Warner">
<meta name="description" content="20.1 Objectives Conduct and interpret a goodness of fit test using both Pearson’s chi-squared and randomization to evaluate the independence between two categorical variables. Explain how the...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 20 Additional Hypothesis Tests | Probability and Statistics for Scientists and Engineers">
<meta property="og:type" content="book">
<meta property="og:image" content="/figures/Cover_Engineers.png">
<meta property="og:description" content="20.1 Objectives Conduct and interpret a goodness of fit test using both Pearson’s chi-squared and randomization to evaluate the independence between two categorical variables. Explain how the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 20 Additional Hypothesis Tests | Probability and Statistics for Scientists and Engineers">
<meta name="twitter:description" content="20.1 Objectives Conduct and interpret a goodness of fit test using both Pearson’s chi-squared and randomization to evaluate the independence between two categorical variables. Explain how the...">
<meta name="twitter:image" content="/figures/Cover_Engineers.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Probability and Statistics for Scientists and Engineers</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="objectives.html">Objectives</a></li>
<li class="book-part">Descriptive Statistical Modeling</li>
<li><a class="" href="CS1.html"><span class="header-section-number">1</span> Data Case Study</a></li>
<li><a class="" href="DB.html"><span class="header-section-number">2</span> Data Basics</a></li>
<li><a class="" href="ODCP.html"><span class="header-section-number">3</span> Overview of Data Collection Principles</a></li>
<li><a class="" href="STUDY.html"><span class="header-section-number">4</span> Studies</a></li>
<li><a class="" href="NUMDATA.html"><span class="header-section-number">5</span> Numerical Data</a></li>
<li><a class="" href="CATDATA.html"><span class="header-section-number">6</span> Categorical Data</a></li>
<li class="book-part">Probability Modeling</li>
<li><a class="" href="CS2.html"><span class="header-section-number">7</span> Probability Case Study</a></li>
<li><a class="" href="PROBRULES.html"><span class="header-section-number">8</span> Probability Rules</a></li>
<li><a class="" href="CONDPROB.html"><span class="header-section-number">9</span> Conditional Probability</a></li>
<li><a class="" href="RANDVAR.html"><span class="header-section-number">10</span> Random Variables</a></li>
<li><a class="" href="CONRANDVAR.html"><span class="header-section-number">11</span> Continuous Random Variables</a></li>
<li><a class="" href="DISCRETENAMED.html"><span class="header-section-number">12</span> Named Discrete Distributions</a></li>
<li><a class="" href="CONTNNAMED.html"><span class="header-section-number">13</span> Named Continuous Distributions</a></li>
<li><a class="" href="MULTIDISTS.html"><span class="header-section-number">14</span> Multivariate Distributions</a></li>
<li><a class="" href="MULTIEXP.html"><span class="header-section-number">15</span> Multivariate Expectation</a></li>
<li class="book-part">Inferential Statistical Modeling</li>
<li><a class="" href="CS3.html"><span class="header-section-number">16</span> Hypothesis Testing Case Study</a></li>
<li><a class="" href="HYPTESTSIM.html"><span class="header-section-number">17</span> Hypothesis Testing with Simulation</a></li>
<li><a class="" href="HYPTESTDIST.html"><span class="header-section-number">18</span> Hypothesis Testing with Known Distributions</a></li>
<li><a class="" href="HYPTESTCLT.html"><span class="header-section-number">19</span> Hypothesis Testing with the Central Limit Theorem</a></li>
<li><a class="active" href="ADDTESTS.html"><span class="header-section-number">20</span> Additional Hypothesis Tests</a></li>
<li><a class="" href="ANOVA.html"><span class="header-section-number">21</span> Analysis of Variance</a></li>
<li><a class="" href="CI.html"><span class="header-section-number">22</span> Confidence Intervals</a></li>
<li><a class="" href="BOOT.html"><span class="header-section-number">23</span> Bootstrap</a></li>
<li class="book-part">Predictive Statistical Modeling</li>
<li><a class="" href="CS4.html"><span class="header-section-number">24</span> Linear Regression Case Study</a></li>
<li><a class="" href="LRBASICS.html"><span class="header-section-number">25</span> Linear Regression Basics</a></li>
<li><a class="" href="LRINF.html"><span class="header-section-number">26</span> Linear Regression Inference</a></li>
<li><a class="" href="LRDIAG.html"><span class="header-section-number">27</span> Regression Diagnostics</a></li>
<li><a class="" href="LRSIM.html"><span class="header-section-number">28</span> Simulation-Based Linear Regression</a></li>
<li><a class="" href="LRMULTI.html"><span class="header-section-number">29</span> Multiple Linear Regression</a></li>
<li><a class="" href="LOGREG.html"><span class="header-section-number">30</span> Logistic Regression</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ADDTESTS" class="section level1" number="20">
<h1>
<span class="header-section-number">20</span> Additional Hypothesis Tests<a class="anchor" aria-label="anchor" href="#ADDTESTS"><i class="fas fa-link"></i></a>
</h1>
<div id="objectives-20" class="section level2" number="20.1">
<h2>
<span class="header-section-number">20.1</span> Objectives<a class="anchor" aria-label="anchor" href="#objectives-20"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Conduct and interpret a goodness of fit test using both Pearson’s chi-squared and randomization to evaluate the independence between two categorical variables.</p></li>
<li><p>Explain how the chi-squared distribution relates to the normal distribution, where it is used, and how changing parameters impacts the shape of the distribution.</p></li>
<li><p>Conduct and interpret a hypothesis test for equality of two means and equality of two variances using both permutation and the CLT.</p></li>
<li><p>Conduct and interpret a hypothesis test for paired data.</p></li>
<li><p>Know and check the assumptions for Pearson’s chi-square and two-sample <span class="math inline">\(t\)</span> tests.</p></li>
</ol>
</div>
<div id="introduction-2" class="section level2" number="20.2">
<h2>
<span class="header-section-number">20.2</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>The purpose of the next two chapters is to put all we’ve learned so far in this block into perspective, and to demonstrate a couple of new statistical tests.</p>
<p>Remember that we have been using data to answer research questions. So far, we can do this with hypothesis tests, using several different methods. There is a close link between these methods, and the steps of hypothesis testing have remained the same no matter which method is used. The key ideas have been to generate a single number metric to use in answering our research question, and then to obtain the sampling distribution of this metric.</p>
<p>In obtaining the sampling distribution, we used randomization as an approximation to permutation exact tests, probability models, and mathematical models. Each of these had different assumptions and different areas where they could be applied. In some cases, several methods can be applied to the problem to get a sense of the robustness to different assumptions. For example, if you run a randomization test and a test using the CLT, and they both give you similar results, you can feel better about your decision.</p>
<p>Finding a single number metric to answer our research question can be difficult. For example, in Chapter <a href="HYPTESTSIM.html#HYPTESTSIM">17</a>, we wanted to determine if the distribution of lengths of commercials for premium and basic channels was different. The difference in means has been used for historical reasons, and we now know that is because of the need to use the <span class="math inline">\(t\)</span> distribution. But is this the best way to answer the question? Because we wanted to think creatively, we ended up using the ratio of median lengths as our single number metric. However, there are other ways in which the distribution of lengths of commercials can differ.</p>
<p>Jack Welch was the CEO of GE for years and he made the claim that customers don’t care about the average, but they do care about variability. The average temperature setting of your GE refrigerator could be off and you would adapt. However, if the temperature had great variability, then you would be upset. So metrics that incorporate variability might be good. In Chapter <a href="HYPTESTSIM.html#HYPTESTSIM">17</a>, we looked at the length of commercials for basic and premium TV channels. In using a randomization test, we assumed in the null hypothesis that there was no difference in the distributions. However, in the alternative hypothesis, we measured the difference in distributions using only medians, a measure of average. The medians of these two populations could be equal, but the distributions could differ in other ways, like variability. We could conduct a separate test for variances, but we have to be careful about multiple comparisons because, in that case, the Type 1 error is inflated.</p>
<p>We also learned that the use of the information in the data impacts the power of the test. In the golf ball example in Chapter <a href="HYPTESTDIST.html#HYPTESTDIST">18</a>, using range as our metric did not give the same power as looking at the differences from expected values under the null hypothesis. There is some mathematical theory, called likelihood ratio tests, that leads to better estimators, but it is beyond the scope of this book. What you can do is create a simulation where you generate data from the alternative hypothesis and then measure the power. This will give you a sense of the quality of your metric. We only briefly looked at measuring power in Chapter <a href="HYPTESTDIST.html#HYPTESTDIST">18</a> and will not go further into this idea in this chapter.</p>
<p>We will continue this block by examining problems with two variables. In the first case, both variables will be categorical and at least one of the categorical variables will have more than two levels. In the second case, we will examine two variables, where one is numeric and the other is categorical, and the categorical variable has more than two levels.</p>
</div>
<div id="other-distributions-for-estimators" class="section level2" number="20.3">
<h2>
<span class="header-section-number">20.3</span> Other distributions for estimators<a class="anchor" aria-label="anchor" href="#other-distributions-for-estimators"><i class="fas fa-link"></i></a>
</h2>
<p>In Chapter <a href="HYPTESTCLT.html#HYPTESTCLT">19</a>, we discussed the <span class="math inline">\(t\)</span> distribution, a different sampling distribution that is based on the CLT or normality assumption. In theoretical statistics, we often mathematically derive the sampling distribution by obtaining a sample statistic, determining the distribution of that statistic under certain conditions, and using that information to make a statement about the population parameter. We now discuss another commonly used sampling distribution: the chi-squared distribution.</p>
<div id="chi-squared" class="section level3" number="20.3.1">
<h3>
<span class="header-section-number">20.3.1</span> Chi-squared<a class="anchor" aria-label="anchor" href="#chi-squared"><i class="fas fa-link"></i></a>
</h3>
<p>Recall the central limit theorem tells us that for reasonably large sample sizes, <span class="math inline">\(\bar{X} \overset{approx}{\sim} \textsf{Norm}(\mu, \sigma/\sqrt{n})\)</span>. This expression involves two unknowns: <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. In the case of binary data, the population variance is a function of the population proportion <span class="math inline">\(\left(Var(X)=\pi(1-\pi)\right)\)</span>, so there is really just one unknown, the population mean <span class="math inline">\(\pi\)</span>. This can be estimated with the sample proportion, <span class="math inline">\(p\)</span>.</p>
<p>In the case of continuous data, the population mean can be estimated with <span class="math inline">\(\bar{x}\)</span>. The population variance would need to be estimated as well. Let <span class="math inline">\(S^2\)</span> be defined as:</p>
<p><span class="math display">\[
S^2 = {\sum (X_i - \bar{X})^2 \over n - 1}
\]</span></p>
<p>This is an unbiased estimate for <span class="math inline">\(\sigma^2\)</span>, meaning that, on average, the estimator above will equal the true value we are trying to estimate (i.e., the true population variance). The sampling distribution of <span class="math inline">\(S^2\)</span> can be found using the following lemma.</p>
<blockquote>
<p>Lemma: Let <span class="math inline">\(X_1, X_2, ..., X_n\)</span> be an i.i.d. sequence of random variables from a normal population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Then,<br><span class="math display">\[
{(n-1) S^2\over \sigma^2} \sim \textsf{Chisq}(n - 1)
\]</span></p>
</blockquote>
<p>The <span class="math inline">\(\textsf{Chisq}(n-1)\)</span> distribution is read as the “chi-squared” distribution (“chi” is pronounced “kye”). This can also be written as <span class="math inline">\(\chi^2 (n-1)\)</span>. The chi-squared distribution has one parameter: degrees of freedom. The chi-squared distribution is used in other contexts such as goodness of fit problems, like the golf ball example from Chapter <a href="HYPTESTDIST.html#HYPTESTDIST">18</a>.</p>
<p>The proof of this lemma is outside the scope of this book, but it is not terribly complicated. It follows from the fact that the sum of <span class="math inline">\(n\)</span> squared random variables, each with the standard normal distribution, follows the chi-squared distribution with <span class="math inline">\(n\)</span> degrees of freedom.</p>
<p>This lemma can be used to draw inferences about <span class="math inline">\(\sigma^2\)</span>. For a particular value of <span class="math inline">\(\sigma^2\)</span>, we know how <span class="math inline">\(S^2\)</span> should behave. So, for a particular value of <span class="math inline">\(S^2\)</span>, we can figure out reasonable values of <span class="math inline">\(\sigma^2\)</span>. In practice, one rarely estimates <span class="math inline">\(\sigma\)</span> for the purpose of inference on <span class="math inline">\(\sigma\)</span>. Typically, we are interested in estimating <span class="math inline">\(\mu\)</span> and we need to account for the added uncertainty by estimating <span class="math inline">\(\sigma\)</span> as well.</p>
<p>The chi-squared distribution takes on positive values and is right skewed. The degrees of freedom influence the shape and location of the distribution. As the degrees of freedom increase, it becomes more similar to a normal distribution. That is, the distribution becomes more symmetric with larger variability, and the center of the distribution moves to the right. Figure <a href="ADDTESTS.html#fig:chisq221-fig">20.1</a> demonstrates these trends.</p>
<div class="figure">
<span style="display:block;" id="fig:chisq221-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/chisq221-fig-1.png" alt="Chi-square distribution for different degrees of freedom." width="672"><p class="caption">
Figure 20.1: Chi-square distribution for different degrees of freedom.
</p>
</div>
</div>
<div id="important-note-1" class="section level3" number="20.3.2">
<h3>
<span class="header-section-number">20.3.2</span> Important Note<a class="anchor" aria-label="anchor" href="#important-note-1"><i class="fas fa-link"></i></a>
</h3>
<p>Just like for the <span class="math inline">\(t\)</span> distribution, the lemma above assumed that each <span class="math inline">\(X_i\)</span> in the sequence of random variables was <em>normally</em> distributed. While the central limit theorem has no such normality assumption, the distribution of the chi-square statistic is subject to the distribution of the underlying population. With large enough expected counts, this assumption is not necessary. Again, there is no magic number, but some resources state that no expected count should be less than one and no more than 20% of the expected counts should be less than five.</p>
<p>One advantage of simulation-based inference methods is that these methods do not rely on any such distributional assumptions. However, the simulation-based methods may have smaller power for the same sample size.</p>
</div>
</div>
<div id="categorical-data-2" class="section level2" number="20.4">
<h2>
<span class="header-section-number">20.4</span> Categorical data<a class="anchor" aria-label="anchor" href="#categorical-data-2"><i class="fas fa-link"></i></a>
</h2>
<p>It is worth spending some time on common approaches to categorical data that you may come across. We have already dealt with categorical data to some extent in this book. We have performed hypothesis tests for <span class="math inline">\(\pi\)</span>, the population proportion of “success” in binary cases (for example, support for a local measure in a vote). This problem had a single variable. Also, the golf ball example involved counts of four types of golf ball. This is considered categorical data because each observation is characterized by a qualitative value (number on the ball). The data are summarized by counting how many balls in a sample belong to each type. This again was a single variable.</p>
<p>In another scenario, suppose we are presented with two qualitative variables and would like to know if they are independent. For example, in Chapter <a href="HYPTESTSIM.html#HYPTESTSIM">17</a>, we discussed methods for determining whether there was a relationship between blood thinners and survival in patients who received CPR for a heart attack. In this case, we have two categorical variables with two levels each: receiving a blood thinner (treatment vs control) and survival (survived vs died). We have solved this type of problem by looking at a difference in probabilities of survival using randomization and mathematically derived solutions, the CLT. We have also used a hypergeometric distribution to obtain an exact <span class="math inline">\(p\)</span>-value.</p>
<p>We will next explore a scenario that involves categorical data with two variables but where at least one variable has more than two levels. However, note that we are only merely scratching the surface in our studies. You could take an entire course on statistical methods for categorical data. This book is giving you a solid foundation to learn more advanced methods.</p>
<div id="health-evaluation-and-linkage-to-primary-care" class="section level3" number="20.4.1">
<h3>
<span class="header-section-number">20.4.1</span> Health evaluation and linkage to primary care<a class="anchor" aria-label="anchor" href="#health-evaluation-and-linkage-to-primary-care"><i class="fas fa-link"></i></a>
</h3>
<p>The Health Evaluation and Linkage to Primary Care (HELP) study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.</p>
<p>The <code>HELPrct</code> data set is available in the <strong>mosaicData</strong> package. There are three substances: alcohol, cocaine, and heroin. We’d like to know if there is evidence that the proportions of use for <code>substance</code>, the primary substance of abuse, differ for males and females.</p>
<div class="sourceCode" id="cb562"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"HELPrct"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb563"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HELP_sub</span> <span class="op">&lt;-</span> <span class="va">HELPrct</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">substance</span>, <span class="va">sex</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb564"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="va">substance</span> <span class="op">~</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span>, format <span class="op">=</span> <span class="st">"prop"</span>, margins <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          sex
## substance    female      male
##   alcohol 0.3364486 0.4075145
##   cocaine 0.3831776 0.3208092
##   heroin  0.2803738 0.2716763
##   Total   1.0000000 1.0000000</code></pre>
<div class="sourceCode" id="cb566"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HELP_sub</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_props</span><span class="op">(</span><span class="op">~</span><span class="va">substance</span><span class="op">|</span><span class="va">sex</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:props222-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/props222-fig-1.png" alt="Proportions for primary substance of abuse in the HELP study, faceted by sex." width="672"><p class="caption">
Figure 20.2: Proportions for primary substance of abuse in the HELP study, faceted by sex.
</p>
</div>
<div class="sourceCode" id="cb567"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="co"># gf_labs(x = "Sex", y = "Proportion")</span></span></code></pre></div>
<div class="sourceCode" id="cb568"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HELP_sub</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_props</span><span class="op">(</span><span class="op">~</span><span class="va">sex</span>, fill<span class="op">=</span> <span class="op">~</span><span class="va">substance</span>, position <span class="op">=</span> <span class="st">"fill"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Sex"</span>, y <span class="op">=</span> <span class="st">"Proportion"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:props223-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/props223-fig-1.png" alt="The distribution of primary substance of abuse in the HELP study by sex." width="672"><p class="caption">
Figure 20.3: The distribution of primary substance of abuse in the HELP study by sex.
</p>
</div>
<p>The two-way table and figures <a href="ADDTESTS.html#fig:props222-fig">20.2</a> and <a href="ADDTESTS.html#fig:props223-fig">20.3</a> exhibit modest differences in the primary substance of abuse by sex, but is it statistically significant?</p>
<p>We need a test statistic to determine if there is a difference in primary substance of abuse between males and females.</p>
</div>
<div id="test-statistic" class="section level3" number="20.4.2">
<h3>
<span class="header-section-number">20.4.2</span> Test statistic<a class="anchor" aria-label="anchor" href="#test-statistic"><i class="fas fa-link"></i></a>
</h3>
<p>To help us develop and understand a test statistic, let’s simplify and use a simple theoretical example.</p>
<p>Suppose we have a 2 x 2 contingency table like the one below.</p>
<p><span class="math display">\[
\begin{array}{lcc}
&amp; \mbox{Response 1} &amp; \mbox{Response 2} \\
\mbox{Group 1} &amp; n_{11} &amp; n_{12} \\
\mbox{Group 2} &amp; n_{21} &amp; n_{22}
\end{array}
\]</span></p>
<p>If our null hypothesis is that the two variables are independent, a classical test statistic used is the Pearson chi-squared test statistic (<span class="math inline">\(X^2\)</span>). This is similar to the test statistic we used in our golf ball example in Chapter <a href="HYPTESTDIST.html#HYPTESTDIST">18</a>. Let <span class="math inline">\(e_{ij}\)</span> be the expected count in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column under the null hypothesis. Then the test statistic is the squared difference of the observed and expected counts, divided by the expected count, summed over both levels of each categorical variable. This expression is shown below:</p>
<p><span class="math display">\[
X^2 = \sum_{i = 1}^2 \sum_{j = 1}^2 {(n_{ij} - e_{ij})^2 \over e_{ij}}
\]</span></p>
<p>But how do we find <span class="math inline">\(e_{ij}\)</span>, the expected count, for each cell? What do we expect the count to be under <span class="math inline">\(H_0\)</span>?</p>
<p>To find the expected counts, we recognize that under <span class="math inline">\(H_0\)</span> (independence), a joint probability is equal to the product of the marginal probabilities. Let <span class="math inline">\(\pi_{ij}\)</span> be the probability of an outcome occurring in row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span>. In the absence of any other information, our best guess at <span class="math inline">\(\pi_{ij}\)</span> is <span class="math inline">\(\hat{\pi}_{ij} = {n_{ij}\over n}\)</span>, where <span class="math inline">\(n_{ij}\)</span> is the number of observations occurring in row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span>, and <span class="math inline">\(n\)</span> is the total sample size for the entire table. But under the null hypothesis, we have the assumption of independence. Thus, <span class="math inline">\(\pi_{ij} = \pi_{i+} \pi_{+j}\)</span> where <span class="math inline">\(\pi_{i+}\)</span> represents the total probability of occurring in row <span class="math inline">\(i\)</span> and <span class="math inline">\(\pi_{+j}\)</span> represents the total probability of occurring in column <span class="math inline">\(j\)</span>. Note that <span class="math inline">\(\pi_{i+}\)</span> is estimated by <span class="math inline">\(\hat{\pi}_{i+}\)</span> and</p>
<p><span class="math display">\[
\hat{\pi}_{i+} = {n_{i+}\over n},
\]</span></p>
<p>where <span class="math inline">\(n_{i+}\)</span> is the sample size for row <span class="math inline">\(i\)</span>. This can be found by summing the sample size for all cells in row <span class="math inline">\(i\)</span>.</p>
<p>Thus for our simple 2 x 2 example, we have:</p>
<p><span class="math display">\[
\hat{\pi}_{i+} = {n_{i+}\over n} = {n_{i1}+n_{i2}\over n}
\]</span></p>
<p>Thus, for Group 1 we would have:</p>
<p><span class="math display">\[
\hat{\pi}_{1+} = {n_{1+}\over n} = {n_{11}+n_{12}\over n}
\]</span></p>
<p>So, under <span class="math inline">\(H_0\)</span>, our best guess for <span class="math inline">\(\pi_{ij}\)</span> is:</p>
<p><span class="math display">\[
\hat{\pi}_{ij} = \hat{\pi}_{i+}\hat{\pi}_{+j} = {n_{i+}\over n}{n_{+j}\over n} = {n_{i1}+n_{i2}\over n}{n_{1j}+n_{2j}\over n}
\]</span></p>
<p>Continuing, under <span class="math inline">\(H_0\)</span> the expected cell count is:</p>
<p><span class="math display">\[
e_{ij} = n\hat{\pi}_{ij} = n{n_{i+}\over n}{n_{+j}\over n} = {n_{i+}n_{+j}\over n}
\]</span></p>
<p>This is essentially found by multiplying the row total (the sample size for row <span class="math inline">\(i\)</span>) by the column total (the sample size for column <span class="math inline">\(j\)</span>) and dividing by the overall table total (the total sample size, <span class="math inline">\(n\)</span>).</p>
</div>
<div id="extension-to-larger-tables" class="section level3" number="20.4.3">
<h3>
<span class="header-section-number">20.4.3</span> Extension to larger tables<a class="anchor" aria-label="anchor" href="#extension-to-larger-tables"><i class="fas fa-link"></i></a>
</h3>
<p>The advantage of using the Pearson chi-squared test statistic is that it can easily be extended to larger <strong>contingency tables</strong>, the name given to these tables displaying multiple categorical variables. Suppose we are comparing two categorical variables, one with <span class="math inline">\(r\)</span> levels and the other with <span class="math inline">\(c\)</span> levels. Then,</p>
<p><span class="math display">\[
X^2 = \sum_{i=1}^r \sum_{j=1}^c {(n_{ij} - e_{ij})^2\over e_{ij}}
\]</span></p>
<p>This is exactly the same as before, except that instead of summing over two levels of each categorical variable, we sum over all <span class="math inline">\(r\)</span> and <span class="math inline">\(c\)</span> levels. That is, we sum over all cells in the contingency table.</p>
<p>Under the null hypothesis of independence, the <span class="math inline">\(X^2\)</span> test statistic follows the chi-squared distribution with <span class="math inline">\((r-1)\times(c-1)\)</span> degrees of freedom.</p>
<div id="assumptions" class="section level4" number="20.4.3.1">
<h4>
<span class="header-section-number">20.4.3.1</span> Assumptions<a class="anchor" aria-label="anchor" href="#assumptions"><i class="fas fa-link"></i></a>
</h4>
<p>Note that to use this test statistic, the expected cell counts, each <span class="math inline">\(e_{ij}\)</span>, must be reasonably large. In fact, no <span class="math inline">\(e_{ij}\)</span> should be less than one and no more than 20% of the <span class="math inline">\(e_{ij}\)</span>’s should be less than five. If this occurs, we should combine cells or look for a different test.</p>
<p>This may all look too abstract, so let’s break it down with an example.</p>
</div>
</div>
<div id="test-statistic-for-the-help-example" class="section level3" number="20.4.4">
<h3>
<span class="header-section-number">20.4.4</span> Test statistic for the HELP example<a class="anchor" aria-label="anchor" href="#test-statistic-for-the-help-example"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s return to the Health Evaluation and Linkage to Primary Care data set. There are two levels of the <code>sex</code> variable, female and male. There are three levels of the <code>substance</code> variable: alcohol, cocaine, and heroin. A two-way contingency table is shown below.</p>
<div class="sourceCode" id="cb569"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          sex
## substance female male
##   alcohol     36  141
##   cocaine     41  111
##   heroin      30   94</code></pre>
<p>To find the Pearson chi-squared test statistic (<span class="math inline">\(X^2\)</span>), we need to figure out the expected count for each cell, <span class="math inline">\(e_{ij}\)</span>, under <span class="math inline">\(H_0\)</span>. Recall that under <span class="math inline">\(H_0\)</span>, the two variables are independent. It’s helpful to add the row and column totals prior to finding expected counts:</p>
<div class="sourceCode" id="cb571"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span>, margins <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          sex
## substance female male Total
##   alcohol     36  141   177
##   cocaine     41  111   152
##   heroin      30   94   124
##   Total      107  346   453</code></pre>
<p>Under the assumption of independence, <span class="math inline">\(H_0\)</span>, the expected count for each cell is equal to the row sum multiplied by the column sum divided by the overall table sum. So, the expected count for the cell representing females who abuse alcohol is</p>
<p><span class="math display">\[
e_{11} = {177*107 \over 453} = 41.81
\]</span></p>
<p>Continuing in this fashion yields the following table of expected counts:</p>
<pre><code>##          sex
## substance   female      male
##   alcohol 41.80795 135.19205
##   cocaine 35.90287 116.09713
##   heroin  29.28918  94.71082</code></pre>
<p>Now, we can find the value of the test statistic, <span class="math inline">\(X^2\)</span>:</p>
<p><span class="math display">\[\begin{multline}
X^2 = {(36 - 41.81)^2 \over 41.81} + {(141 - 135.19)^2 \over 135.19} + {(41 - 35.90)^2 \over 35.90} \\ + {(111 - 116.10)^2 \over 116.10} + {(30 - 29.29)^2 \over 29.29} + {(94 - 94.71)^2 \over 94.71}
\end{multline}\]</span></p>
<p>As you can probably tell, <span class="math inline">\(X^2\)</span> is essentially comparing the observed counts with the expected counts under <span class="math inline">\(H_0\)</span>. The larger the difference between observed and expected count, the larger the value of <span class="math inline">\(X^2\)</span>. It is normalized by dividing by the expected counts since more data in a cell leads to a larger contribution to the sum. Under <span class="math inline">\(H_0\)</span>, this statistic follows the chi-squared distribution with <span class="math inline">\((r-1)\times(c-1)\)</span> degrees of freedom (<span class="math inline">\(r\)</span> is the number of rows and <span class="math inline">\(c\)</span> is the number of columns). In our example, we have <span class="math inline">\((3 - 1)\times (2 - 1) = 2\)</span> degrees of freedom.</p>
</div>
<div id="calculate-the-p-value" class="section level3" number="20.4.5">
<h3>
<span class="header-section-number">20.4.5</span> Calculate the <span class="math inline">\(p\)</span>-value<a class="anchor" aria-label="anchor" href="#calculate-the-p-value"><i class="fas fa-link"></i></a>
</h3>
<p>We can find the Pearson chi-squared test statistic (<span class="math inline">\(X^2\)</span>) and corresponding <span class="math inline">\(p\)</span>-value from the chi-squared distribution in <code>R</code> in a couple of different ways. If we had to enter the data in <code>R</code>, we could simply create vectors of the expected and observed counts.</p>
<div class="sourceCode" id="cb574"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">o</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">36</span>, <span class="fl">141</span>, <span class="fl">41</span>, <span class="fl">111</span>, <span class="fl">30</span>, <span class="fl">94</span><span class="op">)</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">41.81</span>, <span class="fl">135.19</span>, <span class="fl">35.90</span>, <span class="fl">116.10</span>, <span class="fl">29.29</span>, <span class="fl">94.71</span><span class="op">)</span></span>
<span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">o</span> <span class="op">-</span> <span class="va">e</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">e</span><span class="op">)</span></span>
<span><span class="va">x2</span></span></code></pre></div>
<pre><code>## [1] 2.02814</code></pre>
<p>Note that the chi-squared test statistic is a sum of squared differences. Thus, its distribution, a chi-squared distribution, is skewed right and bounded on the left at zero. A departure from the null hypothesis means larger differences between observed and expected counts, and hence, a larger test statistic value. That is, a value further in the right tail of the distribution. Thus, we find the <span class="math inline">\(p\)</span>-value by calculating the probability in the upper tail of the chi-square distribution. We do this by subtracting the CDF from one.</p>
<div class="sourceCode" id="cb576"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">x2</span>, df <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.3627397</code></pre>
<p>The large <span class="math inline">\(p\)</span>-value suggests there is not enough evidence to say these two variables are dependent.</p>
<p>Of course, there is also a built-in function in <code>R</code> that will make the calculations easier. It is <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code>.</p>
<div class="sourceCode" id="cb578"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          sex
## substance female male
##   alcohol     36  141
##   cocaine     41  111
##   heroin      30   94</code></pre>
<div class="sourceCode" id="cb580"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  tally(~substance + sex, data = HELPrct)
## X-squared = 2.0264, df = 2, p-value = 0.3631</code></pre>
<p>We can extract just the table of expected counts:</p>
<div class="sourceCode" id="cb582"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">$</span><span class="va">expected</span></span></code></pre></div>
<pre><code>##          sex
## substance   female      male
##   alcohol 41.80795 135.19205
##   cocaine 35.90287 116.09713
##   heroin  29.28918  94.71082</code></pre>
<p>We can also extract just the test statistic, which we will for permutation tests:</p>
<div class="sourceCode" id="cb584"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/tally.html">tally</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">$</span><span class="va">statistic</span></span></code></pre></div>
<pre><code>## X-squared 
##  2.026361</code></pre>
<p>We can calculate just the test statistic by using the <code><a href="https://www.mosaic-web.org/mosaic/reference/chisq.html">chisq()</a></code> function as well:</p>
<div class="sourceCode" id="cb586"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/chisq.html">chisq</a></span><span class="op">(</span><span class="op">~</span><span class="va">substance</span> <span class="op">+</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span></span></code></pre></div>
<pre><code>## X.squared 
##  2.026361</code></pre>
</div>
<div id="permutation-test" class="section level3" number="20.4.6">
<h3>
<span class="header-section-number">20.4.6</span> Permutation test<a class="anchor" aria-label="anchor" href="#permutation-test"><i class="fas fa-link"></i></a>
</h3>
<p>We will complete our analysis of the HELP data using a randomization, or approximate permutation, test. First, let’s write the hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: The variables sex and substance are independent.<br><span class="math inline">\(H_a\)</span>: The variables sex and substance are dependent.</p>
<p>We will use the chi-squared test statistic as our test statistic for the randomization test. We could use a different test statistic, such as the absolute value function instead of the square function, but then we would need to write a custom function.</p>
<p>Let’s calculate the observed value of the test statistic:</p>
<div class="sourceCode" id="cb588"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/chisq.html">chisq</a></span><span class="op">(</span><span class="va">substance</span> <span class="op">~</span> <span class="va">sex</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span></span>
<span><span class="va">obs</span></span></code></pre></div>
<pre><code>## X.squared 
##  2.026361</code></pre>
<p>Notice that we can also use <code>chisq(~substance + sex, data = HELPrct)</code> to get the same result.</p>
<p>Next, we will use a randomization process to find the sampling distribution of our test statistic.</p>
<div class="sourceCode" id="cb590"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2720</span><span class="op">)</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/do.html">do</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/chisq.html">chisq</a></span><span class="op">(</span><span class="va">substance</span> <span class="op">~</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/resample.html">shuffle</a></span><span class="op">(</span><span class="va">sex</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">HELPrct</span><span class="op">)</span></span></code></pre></div>
<p>Figure <a href="ADDTESTS.html#fig:hist224-fig">20.4</a> is a visual summary of the results, which helps us to gain some intuition about the <span class="math inline">\(p\)</span>-value. We also plot the theoretical chi-squared distribution as a dark blue overlay. The observed test statistic value is shown as a red line.</p>
<div class="sourceCode" id="cb591"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dhistogram</span><span class="op">(</span><span class="op">~</span><span class="va">X.squared</span>, fill <span class="op">=</span> <span class="st">"cyan"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">obs</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dist</span><span class="op">(</span><span class="st">"chisq"</span>, df <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"darkblue"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Sampling distribution of chi-squared test statistic"</span>,</span>
<span>          subtitle <span class="op">=</span> <span class="st">"For the variables sex and substance in the HELPrct data set"</span>,</span>
<span>          x <span class="op">=</span> <span class="st">"Test statistic"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:hist224-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/hist224-fig-1.png" alt="Sampling distribution of chi-squared test statistic from randomization test." width="672"><p class="caption">
Figure 20.4: Sampling distribution of chi-squared test statistic from randomization test.
</p>
</div>
<p>We find the <span class="math inline">\(p\)</span>-value using <code><a href="https://rdrr.io/pkg/mosaicCore/man/prop.html">prop1()</a></code>.</p>
<div class="sourceCode" id="cb592"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/prop.html">prop1</a></span><span class="op">(</span><span class="op">(</span><span class="op">~</span><span class="va">X.squared</span> <span class="op">&gt;=</span> <span class="va">obs</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">results</span><span class="op">)</span></span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.3536464</code></pre>
<p>We don’t double this value because the chi-squared test is a one-sided test, due to the fact that we squared the differences. A departure from the null hypothesis means larger differences between observed and expected counts, and hence, a larger test statistic value. Thus, we are only interested in the upper (right) tail of the distribution.</p>
<p>Based on this <span class="math inline">\(p\)</span>-value, we fail to reject the null hypothesis that the variables are independent. This <span class="math inline">\(p\)</span>-value is very similar to the <span class="math inline">\(p\)</span>-value we found in the previous section for the Pearson’s chi-squared test, leading us to the same conclusion.</p>
<p>Note that in the randomization test, we shuffled the variable <code>sex</code> over many replications and calculated a value of the test statistic for each replication. We did this shuffling because the null hypothesis assumed independence of the two variables. This process led to an empirical estimate of the sampling distribution, shown in Figure <a href="ADDTESTS.html#fig:hist224-fig">20.4</a>. Earlier in the chapter, using the Pearson’s chi-squared test, under the null hypothesis and the appropriate assumptions, the sampling distribution was a chi-squared distribution, shown by the dark blue line in the previous graph. We used it to calculate the <span class="math inline">\(p\)</span>-value directly.</p>
<p>Now that we’ve learned how to deal with two categorical variables, where at least one has more than two levels, we also want to consider situations where we have one categorical and one numerical variable.</p>
</div>
</div>
<div id="numerical-data-3" class="section level2" number="20.5">
<h2>
<span class="header-section-number">20.5</span> Numerical data<a class="anchor" aria-label="anchor" href="#numerical-data-3"><i class="fas fa-link"></i></a>
</h2>
<p>Sometimes we want to compare means across groups. In this case, we have two variables, where one is continuous and the other is categorical. In this section, we will learn how to compare means for two different categories. We can do this using a randomization test, or using the CLT in what is called a two-sample <span class="math inline">\(t\)</span>-test. The hypotheses are:</p>
<p><span class="math inline">\(H_0\)</span>: The mean outcome is the same for both groups, or the difference in the means between the two groups is zero. In statistical notation, <span class="math inline">\(\mu_1 = \mu_2\)</span> or <span class="math inline">\(\mu_1 - \mu_2 = 0\)</span>, where <span class="math inline">\(\mu_1\)</span> represents the mean for group 1 and <span class="math inline">\(\mu_2\)</span> represents the mean for group 2.<br><span class="math inline">\(H_A\)</span>: The mean outcome for the two groups is different, or the difference in means is different from zero.</p>
<p>A two-sample <span class="math inline">\(t\)</span>-test can be used to test for a difference in two means when the following conditions are met:</p>
<ol style="list-style-type: lower-roman">
<li>The data in each group meet the conditions for using the <span class="math inline">\(t\)</span> distribution, i.e., the observations are independent and come from a nearly normal distribution.<br>
</li>
<li>The two groups are independent of each other.</li>
</ol>
<p>In general, the test statistic for a two-sample <span class="math inline">\(t\)</span>-test is:</p>
<p><span class="math display">\[
T = {\text{point estimate - null value} \over\text{standard error}} = {(\bar{X}_1 - \bar{X}_2) - 0 \over \sqrt{{S_1^2\over n_1} + {S_2^2\over n_2}}}
\]</span></p>
<p>The point estimate of interest is the difference between the sample means, and the null value is the hypothesized difference between the sample means, i.e., zero.</p>
<p>There are variations of this test statistic that use a pooled standard deviation or allow for paired, dependent, data, but these settings are beyond the scope of this book. We leave it to the reader to find out more about those situations as needed, and remind the reader that a lot of data analysis (and the associated code) is done via internet search.</p>
<p>When the null hypothesis (no difference in sample means) is true and the conditions are met, the test statistic <span class="math inline">\(T\)</span> has a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(df \approx \min(n_1 - 1, n_2 - 1)\)</span>. More complicated calculations can be done to find the <em>exact</em> degrees of freedom, but this is again beyond the scope of this book. We leave it to the reader to find out more.</p>
<p>Let’s now turn to an example to illustrate this new statistical test.</p>
<div id="mlb-batting-performance" class="section level3" number="20.5.1">
<h3>
<span class="header-section-number">20.5.1</span> MLB batting performance<a class="anchor" aria-label="anchor" href="#mlb-batting-performance"><i class="fas fa-link"></i></a>
</h3>
<p>We would like to discern whether there are real differences between the batting performance of baseball players according to their position. We will use a data set <code>mlbbat10</code> from the <strong>openintro</strong> package. It is available in the file <code>mlb_obp.csv</code> which has been modified from the original data set to include only those players with more than 200 at bats. The batting performance will be measured by on-base percentage, <code>obp</code>. The on-base percentage roughly represents the fraction of times a player successfully gets on base or hits a home run. There are four positions in the data, but we are only interested in outfielders (<code>OF</code>) and infielders (<code>IF</code>) for now.</p>
<p>Read the data into <code>R</code> and filter by position.</p>
<div class="sourceCode" id="cb594"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlb_obp_subset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/mlb_obp.csv"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">position</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"IF"</span>, <span class="st">"OF"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Let’s review our data:</p>
<div class="sourceCode" id="cb595"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/inspect.html">inspect</a></span><span class="op">(</span><span class="va">mlb_obp_subset</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## categorical variables:  
##       name     class levels   n missing
## 1 position character      2 274       0
##                                    distribution
## 1 IF (56.2%), OF (43.8%)                       
## 
## quantitative variables:  
##   name   class   min   Q1 median    Q3   max     mean         sd   n missing
## 1  obp numeric 0.174 0.31  0.331 0.353 0.437 0.332719 0.03392522 274       0</code></pre>
<p>Next, change the variable <code>position</code> to a factor to make it easier to work with.</p>
<div class="sourceCode" id="cb597"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlb_obp_subset</span> <span class="op">&lt;-</span> <span class="va">mlb_obp_subset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>position <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">position</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Let’s look at summary statistics of the on-base percentage by position.</p>
<div class="sourceCode" id="cb598"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">favstats</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   position   min      Q1 median      Q3   max     mean         sd   n missing
## 1       IF 0.174 0.30800 0.3270 0.35275 0.437 0.331526 0.03709504 154       0
## 2       OF 0.265 0.31475 0.3345 0.35300 0.411 0.334250 0.02944394 120       0</code></pre>
<p>The means for both groups are pretty similar to each other.</p>
<blockquote>
<p><strong>Exercise</strong>:
The null hypothesis under consideration is the following: <span class="math inline">\(\mu_{OF} = \mu_{IF}\)</span> or <span class="math inline">\(\mu_{OF} - \mu_{IF} = 0\)</span>.
Write the null and corresponding alternative hypotheses in plain language.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;: The average on-base percentage for infielders and outfielders is equal, or the average difference between on-base percentage for infielders and outfielders is zero. &lt;span class="math inline"&gt;\(H_A\)&lt;/span&gt;: The average on-base percentage for infielders and outfielders is different.&lt;/p&gt;'><sup>90</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:
If we have all the data for the 2010 season, why do we need a hypothesis test? What is the population of interest?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;If we are only making decisions or claims about the 2010 season, we do not need hypothesis testing. We can simply use summary statistics. However, if we want to generalize to other years or other leagues, then we need to conduct a hypothesis test.&lt;/p&gt;"><sup>91</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br>
Construct side-by-side boxplots.</p>
</blockquote>
<p>Figure <a href="ADDTESTS.html#fig:box225-fig">20.5</a> shows the side-by-side boxplots for infielders and outfielders.</p>
<div class="sourceCode" id="cb600"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlb_obp_subset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_boxplot</span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Position Played"</span>, y <span class="op">=</span> <span class="st">"On-Base Percentage"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Comparison of OBP for infielders and outfielders"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:box225-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/box225-fig-1.png" alt="Boxplots of on-base percentage by position played." width="672"><p class="caption">
Figure 20.5: Boxplots of on-base percentage by position played.
</p>
</div>
<p>We must verify the assumptions before proceeding with a two-sample <span class="math inline">\(t\)</span>-test. We can assume that MLB players in 2010 are a representative sample of MLB players from other years. Also, the sample size for both groups is over 100, so we feel good about independence of observations within groups. There is no reason to believe that the data across groups, infielders versus outfielders, are not independent of each other. Figures <a href="ADDTESTS.html#fig:dens226-fig">20.6</a> and <a href="ADDTESTS.html#fig:qq227-fig">20.7</a> show density curves and quantile-quantile plots for the on-base percentage by position played. There are no major outliers or other causes for concern. The data within each group appears nearly normal.</p>
<div class="sourceCode" id="cb601"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlb_obp_subset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dens</span><span class="op">(</span><span class="op">~</span><span class="va">obp</span>, color <span class="op">=</span> <span class="op">~</span><span class="va">position</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:dens226-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/dens226-fig-1.png" alt="Density curves of on-base percentage by position played." width="672"><p class="caption">
Figure 20.6: Density curves of on-base percentage by position played.
</p>
</div>
<div class="sourceCode" id="cb602"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mlb_obp_subset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_qq</span><span class="op">(</span><span class="op">~</span><span class="va">obp</span> <span class="op">|</span> <span class="va">position</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_qqline</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:qq227-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/qq227-fig-1.png" alt="Quantile-quantile plots of on-base percentage by position played." width="672"><p class="caption">
Figure 20.7: Quantile-quantile plots of on-base percentage by position played.
</p>
</div>
<p>We can now move forward with a two-sample <span class="math inline">\(t\)</span>-test.</p>
<div id="test-statistic-1" class="section level4" number="20.5.1.1">
<h4>
<span class="header-section-number">20.5.1.1</span> Test statistic<a class="anchor" aria-label="anchor" href="#test-statistic-1"><i class="fas fa-link"></i></a>
</h4>
<p>Our test statistic can be found using the summary statistics that we calculated earlier.</p>
<div class="sourceCode" id="cb603"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">favstats</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   position   min      Q1 median      Q3   max     mean         sd   n missing
## 1       IF 0.174 0.30800 0.3270 0.35275 0.437 0.331526 0.03709504 154       0
## 2       OF 0.265 0.31475 0.3345 0.35300 0.411 0.334250 0.02944394 120       0</code></pre>
<p>We’ll treat infielders as group 1, subtracting their mean on-base percentage from that of outfielders. Thus, our observed test statistic is</p>
<p><span class="math display">\[
T = {(\bar{X}_{OF} - \bar{X}_{IF}) - 0 \over \sqrt{{S_{OF}^2\over n_{OF}} + {S_{IF}^2\over n_{IF}}}} = {(0.3343 - 0.3315) - 0 \over \sqrt{{0.0294^2\over 120} + {0.0371^2\over 154}}}
\]</span></p>
<p>We can also calculate this using <code>R</code>.</p>
<div class="sourceCode" id="cb605"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">sd</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span>
<span><span class="va">obs</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/diffmean.html">diffmean</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span> <span class="op">-</span> <span class="fl">0</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">s</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">120</span> <span class="op">+</span> <span class="va">s</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">154</span><span class="op">)</span></span>
<span><span class="va">obs</span></span></code></pre></div>
<pre><code>##  diffmean 
## 0.6776293</code></pre>
<p>Since the conditions for the <span class="math inline">\(t\)</span> distribution are met, under the null hypothesis, our test statistic has a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(\min(120 - 1, 154 - 1) = 119\)</span> degrees of freedom.</p>
</div>
<div id="calculate-the-p-value." class="section level4" number="20.5.1.2">
<h4>
<span class="header-section-number">20.5.1.2</span> Calculate the p-value.<a class="anchor" aria-label="anchor" href="#calculate-the-p-value."><i class="fas fa-link"></i></a>
</h4>
<p>We find the p-value for the two-sample <span class="math inline">\(t\)</span>-test by calculating the probability in the right tail of a <span class="math inline">\(t\)</span> distribution and doubling it.</p>
<div class="sourceCode" id="cb607"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="va">obs</span>, df <span class="op">=</span> <span class="fl">119</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  diffmean 
## 0.4993221</code></pre>
</div>
<div id="draw-a-conclusion." class="section level4" number="20.5.1.3">
<h4>
<span class="header-section-number">20.5.1.3</span> Draw a conclusion.<a class="anchor" aria-label="anchor" href="#draw-a-conclusion."><i class="fas fa-link"></i></a>
</h4>
<p>With such a large <span class="math inline">\(p\)</span>-value, we fail to reject the null hypothesis that the difference in means is zero. We do not have sufficient evidence to say that the mean on-base percentage for infielders and outfielders differs.</p>
</div>
</div>
<div id="two-sample-t-test-in-r" class="section level3" number="20.5.2">
<h3>
<span class="header-section-number">20.5.2</span> Two-sample <span class="math inline">\(t\)</span>-test in <code>R</code><a class="anchor" aria-label="anchor" href="#two-sample-t-test-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>As may be expected, we can also use the built-in <code>R</code> function <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test()</a></code> that was previously discussed in Chapter <a href="HYPTESTCLT.html#HYPTESTCLT">19</a>.</p>
<p>Here, we specify a formula with the numerical variable on the left and the categorical variable on the right. Remember to use <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">help(t_test)</a></code> or <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">?t_test</a></code> to access the <code>R</code> documentation for the <code>t_test</code> function.</p>
<div class="sourceCode" id="cb609"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  obp by position
## t = -0.67763, df = 271.9, p-value = 0.4986
## alternative hypothesis: true difference in means between group IF and group OF is not equal to 0
## 95 percent confidence interval:
##  -0.01063818  0.00519013
## sample estimates:
## mean in group IF mean in group OF 
##         0.331526         0.334250</code></pre>
<p>Our <span class="math inline">\(p\)</span>-value of 0.499 is very similar to the one we got using the <code><a href="https://rdrr.io/r/stats/TDist.html">pt()</a></code> function. You should notice that the test statistic, <span class="math inline">\(t\)</span>, reported here is negative but has the same number value as our test statistic from before. The <code>t_test</code> function subtracted outfielders from infielders, but the <span class="math inline">\(p\)</span>-value is practically the same because of the symmetry of the <span class="math inline">\(t\)</span> distribution. If desired, we could reorder the levels of the <code>position</code> variable so that the results from <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test()</a></code> more closely match our results from finding the <span class="math inline">\(p\)</span>-value directly. You should also notice that the degrees of freedom are much different than the 119 we used previously. The <code>t_test</code> function applies a Welch correction to the degrees of freedom (hence, the “Welch Two Sample t-test” title on the output above) in some situations. We leave the reader to investigate additional options in the <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test()</a></code> function, as discussions of special cases of the two-sample <span class="math inline">\(t\)</span>-test are beyond the scope of this book.</p>
</div>
<div id="randomization-test" class="section level3" number="20.5.3">
<h3>
<span class="header-section-number">20.5.3</span> Randomization test<a class="anchor" aria-label="anchor" href="#randomization-test"><i class="fas fa-link"></i></a>
</h3>
<p>We can repeat the same analysis using a randomization test. We will first use the difference of means as our test statistic, and then, for interest, we’ll use the <span class="math inline">\(t\)</span> statistic as well.</p>
<div id="test-statistic---difference-of-means" class="section level4" number="20.5.3.1">
<h4>
<span class="header-section-number">20.5.3.1</span> Test statistic - difference of means<a class="anchor" aria-label="anchor" href="#test-statistic---difference-of-means"><i class="fas fa-link"></i></a>
</h4>
<p>Let’s calculate the observed test statistic.</p>
<div class="sourceCode" id="cb611"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/diffmean.html">diffmean</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span>
<span><span class="va">obs</span></span></code></pre></div>
<pre><code>##    diffmean 
## 0.002724026</code></pre>
</div>
<div id="calculate-the-p-value-1" class="section level4" number="20.5.3.2">
<h4>
<span class="header-section-number">20.5.3.2</span> Calculate the p-value<a class="anchor" aria-label="anchor" href="#calculate-the-p-value-1"><i class="fas fa-link"></i></a>
</h4>
<p>Now, we’ll conduct the randomization test. Under the null hypothesis, there is no difference in mean on-base percentage between infielders and outfielders. That is, the <code>position</code> label for each player can be shuffled around, and we should still end up with roughly equal mean on-base percentages. We’ll do this many times and plot the results.</p>
<div class="sourceCode" id="cb613"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">807</span><span class="op">)</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/do.html">do</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/diffmean.html">diffmean</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/resample.html">shuffle</a></span><span class="op">(</span><span class="va">position</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span></span></code></pre></div>
<p>Figure <a href="ADDTESTS.html#fig:hist228-fig">20.8</a> is a plot of the sampling distribution of the difference of means from the randomization test. The observed test statistic is shown as a red line.</p>
<div class="sourceCode" id="cb614"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dhistogram</span><span class="op">(</span><span class="op">~</span><span class="va">diffmean</span>, fill <span class="op">=</span> <span class="st">"cyan"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">obs</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Randomization test sampling distribution"</span>, </span>
<span>          subtitle <span class="op">=</span> <span class="st">"Difference of means"</span>, </span>
<span>          x <span class="op">=</span> <span class="st">"Test statistic"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided.</code></pre>
<div class="figure">
<span style="display:block;" id="fig:hist228-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/hist228-fig-1.png" alt="The sampling distribution of the randomization test using the difference of means." width="672"><p class="caption">
Figure 20.8: The sampling distribution of the randomization test using the difference of means.
</p>
</div>
<p>The two-sided <span class="math inline">\(p\)</span>-value is</p>
<div class="sourceCode" id="cb616"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/prop.html">prop1</a></span><span class="op">(</span><span class="op">~</span><span class="op">(</span><span class="va">diffmean</span> <span class="op">&gt;=</span> <span class="va">obs</span><span class="op">)</span>, <span class="va">results</span><span class="op">)</span></span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.4895105</code></pre>
<p>This is very similar to the <span class="math inline">\(p\)</span>-value we obtained using the two-sample <span class="math inline">\(t\)</span>-test.</p>
</div>
<div id="test-statistic---t" class="section level4" number="20.5.3.3">
<h4>
<span class="header-section-number">20.5.3.3</span> Test statistic - <span class="math inline">\(t\)</span><a class="anchor" aria-label="anchor" href="#test-statistic---t"><i class="fas fa-link"></i></a>
</h4>
<p>Now, let’s repeat the analysis, but use the <span class="math inline">\(t\)</span> statistic as our test statistic. We’ll use the following code to extract the <span class="math inline">\(t\)</span> statistic from the <code><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test()</a></code> output and find our observed test statistic.</p>
<div class="sourceCode" id="cb618"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="va">position</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span><span class="op">$</span><span class="va">statistic</span></span>
<span><span class="va">obs</span></span></code></pre></div>
<pre><code>##          t 
## -0.6776293</code></pre>
</div>
<div id="calculate-the-p-value-2" class="section level4" number="20.5.3.4">
<h4>
<span class="header-section-number">20.5.3.4</span> Calculate the p-value<a class="anchor" aria-label="anchor" href="#calculate-the-p-value-2"><i class="fas fa-link"></i></a>
</h4>
<p>Now, we’ll conduct the randomization test.</p>
<div class="sourceCode" id="cb620"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">526</span><span class="op">)</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/do.html">do</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/ttest.html">t_test</a></span><span class="op">(</span><span class="va">obp</span> <span class="op">~</span> <span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/resample.html">shuffle</a></span><span class="op">(</span><span class="va">position</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">mlb_obp_subset</span><span class="op">)</span><span class="op">$</span><span class="va">statistic</span></span></code></pre></div>
<p>Figure <a href="ADDTESTS.html#fig:hist229-fig">20.9</a> is a plot of the sampling distribution of the <span class="math inline">\(t\)</span> statistic from the randomization test. The observed test statistic is shown as a red line. A <span class="math inline">\(t\)</span> distribution is overlaid as a dark blue line.</p>
<div class="sourceCode" id="cb621"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dhistogram</span><span class="op">(</span><span class="op">~</span><span class="va">t</span>, fill <span class="op">=</span> <span class="st">"cyan"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">obs</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_dist</span><span class="op">(</span><span class="st">"t"</span>, df <span class="op">=</span> <span class="fl">191</span>, color <span class="op">=</span> <span class="st">"darkblue"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Randomization test sampling distribution"</span>, </span>
<span>          subtitle <span class="op">=</span> <span class="st">"t-statistic"</span>, </span>
<span>          x <span class="op">=</span> <span class="st">"Test statistic"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided.</code></pre>
<div class="figure">
<span style="display:block;" id="fig:hist229-fig"></span>
<img src="22-Additional-Hypothesis-Tests_files/figure-html/hist229-fig-1.png" alt="The sampling distribution of the randomization test using the t-statistic." width="672"><p class="caption">
Figure 20.9: The sampling distribution of the randomization test using the t-statistic.
</p>
</div>
<p>The two-sided <span class="math inline">\(p\)</span>-value is</p>
<div class="sourceCode" id="cb623"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/prop.html">prop1</a></span><span class="op">(</span><span class="op">~</span><span class="op">(</span><span class="va">t</span> <span class="op">&lt;=</span> <span class="va">obs</span><span class="op">)</span>, <span class="va">results</span><span class="op">)</span></span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.5954046</code></pre>
<p>You should notice that the <span class="math inline">\(p\)</span>-value for the two-sample <span class="math inline">\(t\)</span>-test is smaller than the <span class="math inline">\(p\)</span>-value obtained here. That is because the <span class="math inline">\(p\)</span>-value for the two-sample <span class="math inline">\(t\)</span>-test involves more assumptions. Still, our results here are consistent with those using the difference of means randomization test and the two-sample <span class="math inline">\(t\)</span>-test.</p>
<p>In the next chapter, we will learn how to use the <span class="math inline">\(F\)</span> statistic and ANOVA to test whether there are differences in more than two means simultaneously.</p>
</div>
</div>
</div>
<div id="homework-problems-19" class="section level2" number="20.6">
<h2>
<span class="header-section-number">20.6</span> Homework Problems<a class="anchor" aria-label="anchor" href="#homework-problems-19"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>
<strong>Golf balls</strong>. Repeat the analysis of the golf ball problem from earlier in the book. This time, we’ll compare the observed proportions to a distribution, sometimes called a chi-squared goodness-of-fit test.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Load the data and tally the data into a table. The data is available in <code>golf_balls.csv</code>.</p></li>
<li><p>Using the function <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code>, conduct a hypothesis test of equally likely distribution of balls. You may have to read the help menu for <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code>.</p></li>
<li><p>Repeat part b), but assume balls with the numbers 1 and 2 occur 30% of the time and balls with the numbers 3 and 4 occur 20% of the time.</p></li>
<li><p>Repeat part c), but use a randomization test this time. You should use <span class="math inline">\(X^2\)</span>, the chi-squared test statistic as your test statistic.</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Test of variance</strong>. We have not performed a test of variance so we will create our own. Use the <code>mlb_obp_subset</code> data set, with only the <code>IF</code> and <code>OF</code> positions, to conduct a test of equality of two variances. The hypotheses are:</li>
</ol>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\sigma^2_{IF} = \sigma^2_{OF}\)</span>. There is no difference in the variance of on-base percentage for infielders and outfielders.<br><span class="math inline">\(H_A\)</span>: <span class="math inline">\(\sigma^2_{IF} \neq \sigma^2_{OF}\)</span>. There is a difference in variances.</p>
<p>Use the difference in sample standard deviations as your test statistic. Using a randomization test, find the <span class="math inline">\(p\)</span>-value and discuss your decision. Make sure to include all steps of a hypothesis test.</p>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Exploration of the chi-squared and <span class="math inline">\(t\)</span> distributions</strong>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>In <code>R</code>, plot the pdf of a random variable with a chi-squared distribution with one degree of freedom. On the same plot, include the pdfs with 5, 10 and 50 degrees of freedom. Describe how the behavior of the pdf changes with increasing degrees of freedom.</p></li>
<li><p>Repeat part (a) with the <span class="math inline">\(t\)</span> distribution. Add the pdf of a standard normal random variable as well. What do you notice?</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>
<p><strong>Paired data</strong>. Are textbooks actually cheaper online? Here we compare the price of textbooks at the University of California, Los Angeles (UCLA) bookstore and at Amazon.com. Seventy-three UCLA courses were randomly sampled in Spring 2010, representing less than 10% of all UCLA courses. When a class had multiple books, only the most expensive text was considered. The data is in the file <code>textbooks.csv</code> under the data folder.</p>
<p>Each textbook has two corresponding prices in the data set: one for the UCLA bookstore and one for Amazon. Therefore, each textbook price from the UCLA bookstore has a natural correspondence with a textbook price from Amazon. When two sets of observations have this special correspondence, they are said to be <strong>paired</strong>.</p>
</li>
</ol>
<p>To analyze paired data, it is often useful to look at the difference in outcomes of each pair of observations. In <code>textbooks</code>, we look at the difference in prices, which is represented as the <code>diff</code> variable. It is important that we always subtract using a consistent order; here Amazon prices are always subtracted from UCLA prices.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Is this data tidy? Explain.</p></li>
<li><p>Make a scatterplot of the UCLA price versus the Amazon price. Add a 45 degree line to the plot.</p></li>
<li>
<p>Make a histogram of the differences in price.</p>
<p>The hypotheses are:<br><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{diff}=0\)</span>. There is no difference in the average textbook price.<br><span class="math inline">\(H_A\)</span>: <span class="math inline">\(\mu_{diff} \neq 0\)</span>. There is a difference in average prices.</p>
</li>
<li><p>To use a <span class="math inline">\(t\)</span> distribution, the variable <code>diff</code> has to be independent and normally distributed. Since the 73 books represent less than 10% of the population, the assumption that the random sample is independent is reasonable. Check normality using <code>qqnorsim()</code> from the <strong>openintro</strong> package. It generates 8 qq plots of simulated normal data that you can use to judge the <code>diff</code> variable.</p></li>
<li><p>Run a <span class="math inline">\(t\)</span> test on the <code>diff</code> variable. Report the <span class="math inline">\(p\)</span>-value and conclusion.</p></li>
<li><p>If there is really no difference between book sources, the variable <code>more</code> is binomial and, under the null, the probability of success is <span class="math inline">\(\pi = 0.5\)</span>. Run a hypothesis test using the variable <code>more</code>.</p></li>
<li><p>Could you use a permutation test on this example? Explain.</p></li>
</ol>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="HYPTESTCLT.html"><span class="header-section-number">19</span> Hypothesis Testing with the Central Limit Theorem</a></div>
<div class="next"><a href="ANOVA.html"><span class="header-section-number">21</span> Analysis of Variance</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ADDTESTS"><span class="header-section-number">20</span> Additional Hypothesis Tests</a></li>
<li><a class="nav-link" href="#objectives-20"><span class="header-section-number">20.1</span> Objectives</a></li>
<li><a class="nav-link" href="#introduction-2"><span class="header-section-number">20.2</span> Introduction</a></li>
<li>
<a class="nav-link" href="#other-distributions-for-estimators"><span class="header-section-number">20.3</span> Other distributions for estimators</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#chi-squared"><span class="header-section-number">20.3.1</span> Chi-squared</a></li>
<li><a class="nav-link" href="#important-note-1"><span class="header-section-number">20.3.2</span> Important Note</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#categorical-data-2"><span class="header-section-number">20.4</span> Categorical data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#health-evaluation-and-linkage-to-primary-care"><span class="header-section-number">20.4.1</span> Health evaluation and linkage to primary care</a></li>
<li><a class="nav-link" href="#test-statistic"><span class="header-section-number">20.4.2</span> Test statistic</a></li>
<li><a class="nav-link" href="#extension-to-larger-tables"><span class="header-section-number">20.4.3</span> Extension to larger tables</a></li>
<li><a class="nav-link" href="#test-statistic-for-the-help-example"><span class="header-section-number">20.4.4</span> Test statistic for the HELP example</a></li>
<li><a class="nav-link" href="#calculate-the-p-value"><span class="header-section-number">20.4.5</span> Calculate the \(p\)-value</a></li>
<li><a class="nav-link" href="#permutation-test"><span class="header-section-number">20.4.6</span> Permutation test</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#numerical-data-3"><span class="header-section-number">20.5</span> Numerical data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#mlb-batting-performance"><span class="header-section-number">20.5.1</span> MLB batting performance</a></li>
<li><a class="nav-link" href="#two-sample-t-test-in-r"><span class="header-section-number">20.5.2</span> Two-sample \(t\)-test in R</a></li>
<li><a class="nav-link" href="#randomization-test"><span class="header-section-number">20.5.3</span> Randomization test</a></li>
</ul>
</li>
<li><a class="nav-link" href="#homework-problems-19"><span class="header-section-number">20.6</span> Homework Problems</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/blob/master/22-Additional-Hypothesis-Tests.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/edit/master/22-Additional-Hypothesis-Tests.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Probability and Statistics for Scientists and Engineers</strong>" was written by Matthew Davis, Brianna Hitt, Ken Horton, Kris Pruitt, Bradley Warner. It was last built on 2022-07-21.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
