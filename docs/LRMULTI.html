<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 29 Multiple Linear Regression | Probability and Statistics for Scientists and Engineers</title>
<meta name="author" content="Matthew Davis">
<meta name="author" content="Brianna Hitt">
<meta name="author" content="Ken Horton">
<meta name="author" content="Kris Pruitt">
<meta name="author" content="Bradley Warner">
<meta name="description" content="29.1 Objectives Create and interpret a model with multiple predictors and check assumptions. Generate and interpret confidence intervals for estimates. Explain adjusted \(R^2\) and...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 29 Multiple Linear Regression | Probability and Statistics for Scientists and Engineers">
<meta property="og:type" content="book">
<meta property="og:image" content="/figures/Cover_Engineers.png">
<meta property="og:description" content="29.1 Objectives Create and interpret a model with multiple predictors and check assumptions. Generate and interpret confidence intervals for estimates. Explain adjusted \(R^2\) and...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 29 Multiple Linear Regression | Probability and Statistics for Scientists and Engineers">
<meta name="twitter:description" content="29.1 Objectives Create and interpret a model with multiple predictors and check assumptions. Generate and interpret confidence intervals for estimates. Explain adjusted \(R^2\) and...">
<meta name="twitter:image" content="/figures/Cover_Engineers.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Probability and Statistics for Scientists and Engineers</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="objectives.html">Objectives</a></li>
<li class="book-part">Descriptive Statistical Modeling</li>
<li><a class="" href="CS1.html"><span class="header-section-number">1</span> Data Case Study</a></li>
<li><a class="" href="DB.html"><span class="header-section-number">2</span> Data Basics</a></li>
<li><a class="" href="ODCP.html"><span class="header-section-number">3</span> Overview of Data Collection Principles</a></li>
<li><a class="" href="STUDY.html"><span class="header-section-number">4</span> Studies</a></li>
<li><a class="" href="NUMDATA.html"><span class="header-section-number">5</span> Numerical Data</a></li>
<li><a class="" href="CATDATA.html"><span class="header-section-number">6</span> Categorical Data</a></li>
<li class="book-part">Probability Modeling</li>
<li><a class="" href="CS2.html"><span class="header-section-number">7</span> Probability Case Study</a></li>
<li><a class="" href="PROBRULES.html"><span class="header-section-number">8</span> Probability Rules</a></li>
<li><a class="" href="CONDPROB.html"><span class="header-section-number">9</span> Conditional Probability</a></li>
<li><a class="" href="RANDVAR.html"><span class="header-section-number">10</span> Random Variables</a></li>
<li><a class="" href="CONRANDVAR.html"><span class="header-section-number">11</span> Continuous Random Variables</a></li>
<li><a class="" href="DISCRETENAMED.html"><span class="header-section-number">12</span> Named Discrete Distributions</a></li>
<li><a class="" href="CONTNNAMED.html"><span class="header-section-number">13</span> Named Continuous Distributions</a></li>
<li><a class="" href="MULTIDISTS.html"><span class="header-section-number">14</span> Multivariate Distributions</a></li>
<li><a class="" href="MULTIEXP.html"><span class="header-section-number">15</span> Multivariate Expectation</a></li>
<li class="book-part">Inferential Statistical Modeling</li>
<li><a class="" href="CS3.html"><span class="header-section-number">16</span> Hypothesis Testing Case Study</a></li>
<li><a class="" href="HYPTESTSIM.html"><span class="header-section-number">17</span> Hypothesis Testing with Simulation</a></li>
<li><a class="" href="HYPTESTDIST.html"><span class="header-section-number">18</span> Hypothesis Testing with Known Distributions</a></li>
<li><a class="" href="HYPTESTCLT.html"><span class="header-section-number">19</span> Hypothesis Testing with the Central Limit Theorem</a></li>
<li><a class="" href="ADDTESTS.html"><span class="header-section-number">20</span> Additional Hypothesis Tests</a></li>
<li><a class="" href="ANOVA.html"><span class="header-section-number">21</span> Analysis of Variance</a></li>
<li><a class="" href="CI.html"><span class="header-section-number">22</span> Confidence Intervals</a></li>
<li><a class="" href="BOOT.html"><span class="header-section-number">23</span> Bootstrap</a></li>
<li class="book-part">Predictive Statistical Modeling</li>
<li><a class="" href="CS4.html"><span class="header-section-number">24</span> Linear Regression Case Study</a></li>
<li><a class="" href="LRBASICS.html"><span class="header-section-number">25</span> Linear Regression Basics</a></li>
<li><a class="" href="LRINF.html"><span class="header-section-number">26</span> Linear Regression Inference</a></li>
<li><a class="" href="LRDIAG.html"><span class="header-section-number">27</span> Regression Diagnostics</a></li>
<li><a class="" href="LRSIM.html"><span class="header-section-number">28</span> Simulation-Based Linear Regression</a></li>
<li><a class="active" href="LRMULTI.html"><span class="header-section-number">29</span> Multiple Linear Regression</a></li>
<li><a class="" href="LOGREG.html"><span class="header-section-number">30</span> Logistic Regression</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="LRMULTI" class="section level1" number="29">
<h1>
<span class="header-section-number">29</span> Multiple Linear Regression<a class="anchor" aria-label="anchor" href="#LRMULTI"><i class="fas fa-link"></i></a>
</h1>
<div id="objectives-29" class="section level2" number="29.1">
<h2>
<span class="header-section-number">29.1</span> Objectives<a class="anchor" aria-label="anchor" href="#objectives-29"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Create and interpret a model with multiple predictors and check assumptions.</p></li>
<li><p>Generate and interpret confidence intervals for estimates.</p></li>
<li><p>Explain adjusted <span class="math inline">\(R^2\)</span> and multi-collinearity.</p></li>
<li><p>Interpret regression coefficients for a linear model with multiple predictors.</p></li>
<li><p>Build and interpret models with higher order terms.</p></li>
</ol>
</div>
<div id="introduction-to-multiple-regression" class="section level2" number="29.2">
<h2>
<span class="header-section-number">29.2</span> Introduction to multiple regression<a class="anchor" aria-label="anchor" href="#introduction-to-multiple-regression"><i class="fas fa-link"></i></a>
</h2>
<p>The principles of simple linear regression lay the foundation for more sophisticated regression methods used in a wide range of challenging settings. In our last two chapters, we will explore multiple regression, which introduces the possibility of more than one predictor.</p>
</div>
<div id="multiple-regression" class="section level2" number="29.3">
<h2>
<span class="header-section-number">29.3</span> Multiple regression<a class="anchor" aria-label="anchor" href="#multiple-regression"><i class="fas fa-link"></i></a>
</h2>
<p>Multiple regression extends simple two-variable regression to the case that still has one response but many predictors (denoted <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>, …). The method is motivated by scenarios where many variables may be simultaneously connected to an output.</p>
<p>To explore and explain these ideas, we will consider Ebay auctions of a video game called <strong>Mario Kart</strong> for the Nintendo Wii. The outcome variable of interest is the total price of an auction, which is the highest bid plus the shipping cost. We will try to determine how total price is related to each characteristic in an auction while simultaneously controlling for other variables. For instance, with all other characteristics held constant, are longer auctions associated with higher or lower prices? And, on average, how much more do buyers tend to pay for additional Wii wheels (plastic steering wheels that attach to the Wii controller) in auctions? Multiple regression will help us answer these and other questions.</p>
<p>The data set is in the file <code>mariokart.csv</code> in the <code>data</code> folder. This data set includes results from 141 auctions.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Diez DM, Barr CD, and etinkaya-Rundel M. 2012. &lt;code&gt;openintro&lt;/code&gt;: OpenIntro data sets and supplemental functions. &lt;a href="http://cran.r-project.org/web/packages/openintro" class="uri"&gt;http://cran.r-project.org/web/packages/openintro&lt;/a&gt;&lt;/p&gt;'><sup>105</sup></a> Ten observations from this data set are shown in the <code>R</code> code below. Note that we force the first column to be interpreted as a character string since it is the identification code for each sale and has no numeric meaning. Just as in the case of simple linear regression, multiple regression also allows for categorical variables with many levels. Although we do have this type of variable in this data set, we will leave the discussion of these types of variables in multiple regression for advanced regression or machine learning courses.</p>
<div class="sourceCode" id="cb974"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op">&lt;-</span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/mariokart.csv"</span>, col_types <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://readr.tidyverse.org/reference/parse_atomic.html">col_character</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">mariokart</span>,n<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 10 x 12
##    id        duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1 15037742~        3     20 new       0.99    4        51.6 standa~        1580
##  2 26048337~        7     13 used      0.99    3.99     37.0 firstC~         365
##  3 32043234~        3     16 new       0.99    3.5      45.5 firstC~         998
##  4 28040522~        3     18 new       0.99    0        44   standa~           7
##  5 17039222~        1     20 new       0.01    0        71   media           820
##  6 36019515~        3     19 new       0.99    4        45   standa~      270144
##  7 12047772~        1     13 used      0.01    0        37.0 standa~        7284
##  8 30035550~        1     15 new       1       2.99     54.0 upsGro~        4858
##  9 20039206~        3     29 used      0.99    4        47   priori~          27
## 10 33036416~        7      8 used     20.0     4        50   firstC~         201
## # ... with 3 more variables: stock_photo &lt;chr&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<p>We are only interested in <code>total_pr</code>, <code>cond</code>, <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. These variables are described in the following list:</p>
<ol style="list-style-type: decimal">
<li>
<code>total_pr</code>: final auction price plus shipping costs, in US dollars<br>
</li>
<li>
<code>cond</code>: a two-level categorical factor variable<br>
</li>
<li>
<code>stock_photo</code>: a two-level categorical factor variable<br>
</li>
<li>
<code>duration</code>: the length of the auction, in days, taking values from 1 to 10<br>
</li>
<li>
<code>wheels</code>: the number of Wii wheels included with the auction (a <strong>Wii wheel</strong> is a plastic racing wheel that holds the Wii controller and is an optional but helpful accessory for playing Mario Kart)</li>
</ol>
<div id="a-single-variable-model-for-the-mario-kart-data" class="section level3" number="29.3.1">
<h3>
<span class="header-section-number">29.3.1</span> A single-variable model for the Mario Kart data<a class="anchor" aria-label="anchor" href="#a-single-variable-model-for-the-mario-kart-data"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s fit a linear regression model with the game’s condition as a predictor of auction price. Before we start let’s change <code>cond</code> and <code>stock_photo</code> into factors.</p>
<div class="sourceCode" id="cb976"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op">&lt;-</span> <span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>cond<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">cond</span><span class="op">)</span>,stock_photo<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">stock_photo</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Next let’s summarize the data.</p>
<div class="sourceCode" id="cb977"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/inspect.html">inspect</a></span><span class="op">(</span><span class="va">mariokart</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name     class levels   n missing
## 1          id character    143 143       0
## 2        cond    factor      2 143       0
## 3     ship_sp character      8 143       0
## 4 stock_photo    factor      2 143       0
## 5       title character     80 142       1
##                                    distribution
## 1 110439174663 (0.7%) ...                      
## 2 used (58.7%), new (41.3%)                    
## 3 standard (23.1%), upsGround (21.7%) ...      
## 4 yes (73.4%), no (26.6%)                      
## 5  (%) ...                                     
## 
## quantitative variables:  
##          name   class   min      Q1 median      Q3       max         mean
## 1    duration numeric  1.00   1.000    3.0    7.00     10.00     3.769231
## 2      n_bids numeric  1.00  10.000   14.0   17.00     29.00    13.538462
## 3    start_pr numeric  0.01   0.990    1.0   10.00     69.95     8.777203
## 4     ship_pr numeric  0.00   0.000    3.0    4.00     25.51     3.143706
## 5    total_pr numeric 28.98  41.175   46.5   53.99    326.51    49.880490
## 6 seller_rate numeric  0.00 109.000  820.0 4858.00 270144.00 15898.419580
## 7      wheels numeric  0.00   0.000    1.0    2.00      4.00     1.146853
##             sd   n missing
## 1 2.585693e+00 143       0
## 2 5.878786e+00 143       0
## 3 1.506745e+01 143       0
## 4 3.213179e+00 143       0
## 5 2.568856e+01 143       0
## 6 5.184032e+04 143       0
## 7 8.471829e-01 143       0</code></pre>
<p>Finally, let’s plot the data.</p>
<div class="sourceCode" id="cb979"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">gf_boxplot</span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title<span class="op">=</span><span class="st">"Ebay Auction Prices"</span>,x<span class="op">=</span><span class="st">"Condition"</span>, y<span class="op">=</span><span class="st">"Total Price"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:box301-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/box301-fig-1.png" alt="Total price of Mario Kart on Ebay for each condition." width="672"><p class="caption">
Figure 29.1: Total price of Mario Kart on Ebay for each condition.
</p>
</div>
<p>We have several outliers that may impact our analysis, Figure <a href="LRMULTI.html#fig:box301-fig">29.1</a>.</p>
<p>Now let’s build the model.</p>
<div class="sourceCode" id="cb980"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span>,data<span class="op">=</span><span class="va">mariokart</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb981"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond, data = mariokart)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -18.168  -7.771  -3.148   1.857 279.362 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   53.771      3.329  16.153   &lt;2e-16 ***
## condused      -6.623      4.343  -1.525     0.13    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 25.57 on 141 degrees of freedom
## Multiple R-squared:  0.01622,    Adjusted R-squared:  0.009244 
## F-statistic: 2.325 on 1 and 141 DF,  p-value: 0.1296</code></pre>
<p>The model may be written as</p>
<p><span class="math display">\[
\hat{\text{totalprice}} = 53.771 - 6.623 \times \text{condused}
\]</span></p>
<p>A scatterplot for price versus game condition is shown in Figure <a href="LRMULTI.html#fig:scat301-fig">29.2</a>. Since the predictor is binary, the scatterplot is not appropriate but we will look at it for reference.</p>
<div class="sourceCode" id="cb983"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title<span class="op">=</span><span class="st">"Ebay Auction Prices"</span>,x<span class="op">=</span><span class="st">"Condition"</span>, y<span class="op">=</span><span class="st">"Total Price"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat301-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/scat301-fig-1.png" alt="Scatterplot of total price of Mario Kart on Ebay versus condition." width="672"><p class="caption">
Figure 29.2: Scatterplot of total price of Mario Kart on Ebay versus condition.
</p>
</div>
<p>The largest outlier probably is significantly impacting the relationship in the model. If we find the mean and median for the two groups, we will see this.</p>
<div class="sourceCode" id="cb984"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">cond</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>xbar<span class="op">=</span><span class="fu">mean</span><span class="op">(</span><span class="va">total_pr</span><span class="op">)</span>, stand_dev<span class="op">=</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">sd</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">)</span>,xmedian<span class="op">=</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">median</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   cond   xbar stand_dev xmedian
##   &lt;fct&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 new    53.8      7.44    54.0
## 2 used   47.1     32.7     42.8</code></pre>
<p>It appears that <strong>used</strong> items have a right skewed distribution where their average is higher because of at least one of the outliers.</p>
<p>There are at least two outliers in the plot. Let’s gather more information about them.</p>
<div class="sourceCode" id="cb986"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">total_pr</span> <span class="op">&gt;</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 2 x 12
##   id         duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
## 1 110439174~        7     22 used      1       25.5     327. parcel          115
## 2 130335427~        3     27 used      6.95     4       118. parcel           41
## # ... with 3 more variables: stock_photo &lt;fct&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<p>If you look at the variable <code>title</code> there were additional items in the sale for these two observations. Let’s remove those two outliers and run the model again. Note that the reason we are removing them is not because they are annoying us and messing up our model. It is because we don’t think they are representative of the population of interest. Figure <a href="LRMULTI.html#fig:scat302-fig">29.3</a> is a boxplot of the data with the outliers dropped.</p>
<div class="sourceCode" id="cb988"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart_new</span> <span class="op">&lt;-</span> <span class="va">mariokart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">total_pr</span> <span class="op">&lt;=</span> <span class="fl">100</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">total_pr</span>,<span class="va">cond</span>,<span class="va">stock_photo</span>,<span class="va">duration</span>,<span class="va">wheels</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb989"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     total_pr       cond    stock_photo    duration          wheels     
##  Min.   :28.98   new :59   no : 36     Min.   : 1.000   Min.   :0.000  
##  1st Qu.:41.00   used:82   yes:105     1st Qu.: 1.000   1st Qu.:0.000  
##  Median :46.03                         Median : 3.000   Median :1.000  
##  Mean   :47.43                         Mean   : 3.752   Mean   :1.149  
##  3rd Qu.:53.99                         3rd Qu.: 7.000   3rd Qu.:2.000  
##  Max.   :75.00                         Max.   :10.000   Max.   :4.000</code></pre>
<div class="sourceCode" id="cb991"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mariokart_new</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">gf_boxplot</span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>title<span class="op">=</span><span class="st">"Ebay Auction Prices"</span>,subtitle<span class="op">=</span><span class="st">"Outliers removed"</span>,x<span class="op">=</span><span class="st">"Condition"</span>, y<span class="op">=</span><span class="st">"Total Price"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat302-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/scat302-fig-1.png" alt="Boxplot of total price and condition with outliers removed." width="672"><p class="caption">
Figure 29.3: Boxplot of total price and condition with outliers removed.
</p>
</div>
<div class="sourceCode" id="cb992"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span>,data<span class="op">=</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb993"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond, data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.8911  -5.8311   0.1289   4.1289  22.1489 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  53.7707     0.9596  56.034  &lt; 2e-16 ***
## condused    -10.8996     1.2583  -8.662 1.06e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.371 on 139 degrees of freedom
## Multiple R-squared:  0.3506, Adjusted R-squared:  0.3459 
## F-statistic: 75.03 on 1 and 139 DF,  p-value: 1.056e-14</code></pre>
<p>Notice how much the residual standard error has decreased and likewise the <span class="math inline">\(R\)</span>-squared has increased.</p>
<p>The model may be written as:</p>
<p><span class="math display">\[
\hat{total price} = 53.771 - 10.90 \times condused
\]</span></p>
<p>Now we see that the average price for a used items is $10.90 less than the average of new items.</p>
<blockquote>
<p><strong>Exercise</strong>:<br>
Does the linear model seem reasonable? Which assumptions should you check?</p>
</blockquote>
<p>The model does seem reasonable in the sense that the assumptions on the errors is plausible. The residuals indicate some skewness to the right which may be driven predominantly by the skewness in the new items, Figure <a href="LRMULTI.html#fig:qq301-fig">29.4</a>.</p>
<div class="sourceCode" id="cb995"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mario_mod2</span>,<span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:qq301-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/qq301-fig-1.png" alt="Check of normality using quantile-quantile plot." width="672"><p class="caption">
Figure 29.4: Check of normality using quantile-quantile plot.
</p>
</div>
<p>The normality assumption is somewhat suspect but we have more than 100 data points so the short tails of the distribution are not a concern. The shape of this curve indicates a positive skew.</p>
<div class="sourceCode" id="cb996"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mario_mod2</span>,<span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:diag301-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/diag301-fig-1.png" alt="Residual plot to assess equal variance assumption." width="672"><p class="caption">
Figure 29.5: Residual plot to assess equal variance assumption.
</p>
</div>
<p>From Figure <a href="LRMULTI.html#fig:diag301-fig">29.5</a>, equal variance seems reasonable.</p>
<div class="sourceCode" id="cb997"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mario_mod2</span>,<span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:diag302-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/diag302-fig-1.png" alt="Residual plot for checking leverage points." width="672"><p class="caption">
Figure 29.6: Residual plot for checking leverage points.
</p>
</div>
<p>No high leverage points, Figure <a href="LRMULTI.html#fig:diag302-fig">29.6</a>.</p>
<p>No need to check linearity, we only have two different values for the explanatory variable.</p>
<blockquote>
<p><em>Example</em>: Interpretation<br>
Interpret the coefficient for the game’s condition in the model. Is this coefficient significantly different from 0?</p>
</blockquote>
<p>Note that <code>cond</code> is a two-level categorical variable and the reference level is <code>new</code>. So - 10.90 means that the model predicts an extra $10.90 on average for those games that are new versus those that are used. Examining the regression output, we can see that the <span class="math inline">\(p\)</span>-value for <code>cond</code> is very close to zero, indicating there is strong evidence that the coefficient is different from zero when using this simple one-variable model.</p>
</div>
<div id="including-and-assessing-many-variables-in-a-model" class="section level3" number="29.3.2">
<h3>
<span class="header-section-number">29.3.2</span> Including and assessing many variables in a model<a class="anchor" aria-label="anchor" href="#including-and-assessing-many-variables-in-a-model"><i class="fas fa-link"></i></a>
</h3>
<p>Sometimes there are underlying structures or relationships between predictor variables. For instance, new games sold on Ebay tend to come with more Wii wheels, which may have led to higher prices for those auctions. We would like to fit a model that includes all potentially important variables simultaneously. This would help us evaluate the relationship between a predictor variable and the outcome while controlling for the potential influence of other variables. This is the strategy used in <strong>multiple regression</strong>. While we remain cautious about making any causal interpretations using multiple regression, such models are a common first step in providing evidence of a causal connection.</p>
<p>We want to construct a model that accounts for not only the game condition, but simultaneously accounts for three other variables: <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. This model can be represented as:</p>
<p><span class="math display">\[
\widehat{\text{totalprice}}
    = \beta_0 + \beta_1 \times \text{cond} + \beta_2 \times \text{stockphoto}
    + \beta_3 \times  \text{duration} +
        \beta_4 \times  \text{wheels}
\]</span></p>
<p>or:</p>
<p><span class="math display" id="eq:multilr">\[\begin{equation}
\hat{y}
    = \beta_0 + \beta_1 x_1 + \beta_2 x_2 +
        \beta_3 x_3 + \beta_4 x_4
  \tag{29.1}
\end{equation}\]</span></p>
<p>In Equation <a href="LRMULTI.html#eq:multilr">(29.1)</a>, <span class="math inline">\(y\)</span> represents the total price, <span class="math inline">\(x_1\)</span> indicates whether the game is new, <span class="math inline">\(x_2\)</span> indicates whether a stock photo was used, <span class="math inline">\(x_3\)</span> is the duration of the auction, and <span class="math inline">\(x_4\)</span> is the number of Wii wheels included with the game. Just as with the single predictor case, a multiple regression model may be missing important components or it might not precisely represent the relationship between the outcome and the available explanatory variables. While no model is perfect, we wish to explore the possibility that this model may fit the data reasonably well.</p>
<p>We estimate the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_4\)</span> in the same way as we did in the case of a single predictor. We select <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, …, <span class="math inline">\(b_4\)</span> that minimize the sum of the squared residuals:</p>
<p><span class="math display">\[
\text{SSE} = e_1^2 + e_2^2 + \dots + e_{141}^2
    = \sum_{i=1}^{141} e_i^2
     = \sum_{i=1}^{141} \left(y_i - \hat{y}_i\right)^2
\]</span></p>
<p>In our problem, there are 141 residuals, one for each observation. We use a computer to minimize the sum and compute point estimates.</p>
<div class="sourceCode" id="cb998"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod_multi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<p>The formula <code>total_pr~.</code> uses a <em>dot</em>. This means we want to use all the predictors. We could have also used the following code:</p>
<div class="sourceCode" id="cb999"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod_multi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">+</span><span class="va">stock_photo</span><span class="op">+</span><span class="va">duration</span><span class="op">+</span><span class="va">wheels</span>, data<span class="op">=</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<p>Recall, the <code>+</code> symbol does not mean to literally add the predictors together. It is not a mathematical operation but a formula operation that means to include the predictor.</p>
<p>You can view a summary of the model using the <code>summmary()</code> function.</p>
<div class="sourceCode" id="cb1000"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod_multi</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ ., data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.3788  -2.9854  -0.9654   2.6915  14.0346 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    41.34153    1.71167  24.153  &lt; 2e-16 ***
## condused       -5.13056    1.05112  -4.881 2.91e-06 ***
## stock_photoyes  1.08031    1.05682   1.022    0.308    
## duration       -0.02681    0.19041  -0.141    0.888    
## wheels          7.28518    0.55469  13.134  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.901 on 136 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7108 
## F-statistic: 87.01 on 4 and 136 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Which we can summarize in a tibble using the <strong>broom</strong> package.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:tab301">Table 29.1: </span>Multiple regression coefficients.
</caption>
<thead><tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
41.3415318
</td>
<td style="text-align:right;">
1.7116684
</td>
<td style="text-align:right;">
24.1527693
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
condused
</td>
<td style="text-align:right;">
-5.1305641
</td>
<td style="text-align:right;">
1.0511238
</td>
<td style="text-align:right;">
-4.8810276
</td>
<td style="text-align:right;">
0.0000029
</td>
</tr>
<tr>
<td style="text-align:left;">
stock_photoyes
</td>
<td style="text-align:right;">
1.0803108
</td>
<td style="text-align:right;">
1.0568238
</td>
<td style="text-align:right;">
1.0222241
</td>
<td style="text-align:right;">
0.3084897
</td>
</tr>
<tr>
<td style="text-align:left;">
duration
</td>
<td style="text-align:right;">
-0.0268075
</td>
<td style="text-align:right;">
0.1904122
</td>
<td style="text-align:right;">
-0.1407868
</td>
<td style="text-align:right;">
0.8882467
</td>
</tr>
<tr>
<td style="text-align:left;">
wheels
</td>
<td style="text-align:right;">
7.2851779
</td>
<td style="text-align:right;">
0.5546928
</td>
<td style="text-align:right;">
13.1337172
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
</tbody>
</table></div>
<p>Using this output, Table <a href="LRMULTI.html#tab:tab301">29.1</a>, we identify the point estimates <span class="math inline">\(b_i\)</span> of each <span class="math inline">\(\beta_i\)</span>, just as we did in the one-predictor case.</p>
<blockquote>
<p><strong>Multiple regression model</strong><br>
A multiple regression model is a linear model with many predictors.</p>
</blockquote>
<p>In general, we write the model as</p>
<p><span class="math display">\[
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k %+ \epsilon
\]</span></p>
<p>when there are <span class="math inline">\(k\)</span> predictors. We often estimate the <span class="math inline">\(\beta_i\)</span> parameters using a computer.</p>
<blockquote>
<p><strong>Exercise</strong>:
Write out the the multiple regression model using the point estimates from regression output. How many predictors are there in this model?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(\hat{y} = 41.34 + - 5.13x_1 + 1.08x_2 - 0.03x_3 + 7.29x_4\)&lt;/span&gt;, and there are &lt;span class="math inline"&gt;\(k=4\)&lt;/span&gt; predictor variables.&lt;/p&gt;'><sup>106</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br>
What does <span class="math inline">\(\beta_4\)</span>, the coefficient of variable <span class="math inline">\(x_4\)</span> (Wii wheels), represent? What is the point estimate of <span class="math inline">\(\beta_4\)</span>?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;It is the average difference in auction price for each additional Wii wheel included when holding the other variables constant. The point estimate is &lt;span class="math inline"&gt;\(b_4 = 7.29\)&lt;/span&gt;.&lt;/p&gt;'><sup>107</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br>
Compute the residual of the first observation in the dataframe using the regression equation.</p>
</blockquote>
<div class="sourceCode" id="cb1002"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod_multi</span><span class="op">$</span><span class="va">residuals</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span></code></pre></div>
<pre><code>##        1 
## 1.923402</code></pre>
<p>The <strong>broom</strong> package has a function <code><a href="https://generics.r-lib.org/reference/augment.html">augment()</a></code> that will calculate the predicted and residuals.</p>
<div class="sourceCode" id="cb1004"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb1005"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">mario_mod_multi</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   total_pr cond  stock_photo duration wheels .fitted .resid   .hat .sigma
##      &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;          &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     51.6 new   yes                3      1    49.6   1.92 0.0215   4.92
## # ... with 2 more variables: .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;</code></pre>
<p><span class="math inline">\(e_i = y_i - \hat{y_i} = 51.55 - 49.62 = 1.93\)</span></p>
<blockquote>
<p><em>Example</em>:<br>
We estimated a coefficient for <code>cond</code> as <span class="math inline">\(b_1 = - 10.90\)</span> with a standard error of <span class="math inline">\(SE_{b_1} = 1.26\)</span> when using simple linear regression. Why might there be a difference between that estimate and the one in the multiple regression setting?</p>
</blockquote>
<p>If we examined the data carefully, we would see that some predictors are correlated. For instance, when we estimated the connection of the outcome <code>total_pr</code> and predictor <code>cond</code> using simple linear regression, we were unable to control for other variables like the number of Wii wheels included in the auction. That model was biased by the confounding variable <code>wheels</code>. When we use both variables, this particular underlying and unintentional bias is reduced or eliminated (though bias from other confounding variables may still remain).</p>
<p>The previous example describes a common issue in multiple regression: correlation among predictor variables. We say the two predictor variables are <strong>collinear</strong> (pronounced as <strong>co-linear</strong>) when they are correlated, and this collinearity complicates model estimation. While it is impossible to prevent collinearity from arising in observational data, experiments are usually designed to prevent predictors from being collinear.</p>
<blockquote>
<p><strong>Exercise</strong>:<br>
The estimated value of the intercept is 41.34, and one might be tempted to make some interpretation of this coefficient, such as, it is the model’s predicted price when each of the variables take a value of zero: the game is new, the primary image is not a stock photo, the auction duration is zero days, and there are no wheels included. Is there any value gained by making this interpretation?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Three of the variables (&lt;code&gt;cond&lt;/code&gt;, &lt;code&gt;stock_photo&lt;/code&gt;, and &lt;code&gt;wheels&lt;/code&gt;) do take value 0, but the auction duration is always one or more days. If the auction is not up for any days, then no one can bid on it! That means the total auction price would always be zero for such an auction; the interpretation of the intercept in this setting is not insightful.&lt;/p&gt;"><sup>108</sup></a></p>
</blockquote>
</div>
<div id="inference-1" class="section level3" number="29.3.3">
<h3>
<span class="header-section-number">29.3.3</span> Inference<a class="anchor" aria-label="anchor" href="#inference-1"><i class="fas fa-link"></i></a>
</h3>
<p>From the printout of the model summary, we can see that both the <code>stock_photo</code> and <code>duration</code> variables are not significantly different from zero. Thus we may want to drop them from the model. In a machine learning course, you explore different ways to determine the best model.</p>
<p>Likewise, we could generate confidence intervals for the coefficients:</p>
<div class="sourceCode" id="cb1007"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">mario_mod_multi</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                     2.5 %     97.5 %
## (Intercept)    37.9566036 44.7264601
## condused       -7.2092253 -3.0519030
## stock_photoyes -1.0096225  3.1702442
## duration       -0.4033592  0.3497442
## wheels          6.1882392  8.3821165</code></pre>
<p>This confirms that the <code>stock_photo</code> and <code>duration</code> may not have an impact on total price.</p>
</div>
<div id="adjusted-r2-as-a-better-estimate-of-explained-variance" class="section level3" number="29.3.4">
<h3>
<span class="header-section-number">29.3.4</span> Adjusted <span class="math inline">\(R^2\)</span> as a better estimate of explained variance<a class="anchor" aria-label="anchor" href="#adjusted-r2-as-a-better-estimate-of-explained-variance"><i class="fas fa-link"></i></a>
</h3>
<p>We first used <span class="math inline">\(R^2\)</span> in simple linear regression to determine the amount of variability, we used sum of squares and not mean squared errors, in the response that was explained by the model:
<span class="math display">\[
R^2 = 1 - \frac{\text{sum of squares of residuals}}{\text{sum of squares of the outcome}}
\]</span>
This equation remains valid in the multiple regression framework, but a small enhancement can often be even more informative.</p>
<blockquote>
<p><strong>Exercise</strong>:
The variance of the residuals for the model is <span class="math inline">\(4.901^2\)</span>, and the variance of the total price in all the auctions is 83.06. Estimate the <span class="math inline">\(R^2\)</span> for this model.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(R^2 = 1 - \frac{24.0198}{83.06} = 0.7108\)&lt;/span&gt;.&lt;/p&gt;'><sup>109</sup></a></p>
</blockquote>
<p>To get the <span class="math inline">\(R^2\)</span> we need the sum of squares and not variance, so we multiply by the appropriate degrees of freedom.</p>
<div class="sourceCode" id="cb1009"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="op">(</span><span class="fl">24.0198</span><span class="op">*</span><span class="fl">136</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">83.05864</span><span class="op">*</span><span class="fl">140</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.7190717</code></pre>
<div class="sourceCode" id="cb1011"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod_multi</span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span></span></code></pre></div>
<pre><code>## [1] 0.7190261</code></pre>
<p>This strategy for estimating <span class="math inline">\(R^2\)</span> is acceptable when there is just a single variable. However, it becomes less helpful when there are many variables. The regular <span class="math inline">\(R^2\)</span> is actually a biased estimate of the amount of variability explained by the model. To get a better estimate, we use the adjusted <span class="math inline">\(R^2\)</span>.</p>
<blockquote>
<p><strong>Adjusted <span class="math inline">\(\mathbf{R^2}\)</span> as a tool for model assessment</strong>:<br>
The adjusted <span class="math inline">\(\mathbf{R^2}\)</span> is computed as:
<span class="math display">\[
R_{adj}^{2} = 1-\frac{\text{sum of squares of residuals} / (n-k-1)}{\text{sum of squares of the outcome} / (n-1)}
\]</span>
where <span class="math inline">\(n\)</span> is the number of cases used to fit the model and <span class="math inline">\(k\)</span> is the number of predictor variables in the model.</p>
</blockquote>
<p>Because <span class="math inline">\(k\)</span> is never negative, the adjusted <span class="math inline">\(R^2\)</span> will be smaller – often times just a little smaller – than the unadjusted <span class="math inline">\(R^2\)</span>. The reasoning behind the adjusted <span class="math inline">\(R^2\)</span> lies in the <strong>degrees of freedom</strong> associated with each variance. <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;In multiple regression, the degrees of freedom associated with the variance of the estimate of the residuals is &lt;span class="math inline"&gt;\(n-k-1\)&lt;/span&gt;, not &lt;span class="math inline"&gt;\(n-1\)&lt;/span&gt;. For instance, if we were to make predictions for new data using our current model, we would find that the unadjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; is an overly optimistic estimate of the reduction in variance in the response, and using the degrees of freedom in the adjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; formula helps correct this bias.&lt;/p&gt;'><sup>110</sup></a></p>
<blockquote>
<p><strong>Exercise</strong>:<br>
Suppose you added another predictor to the model, but the variance of the errors didn’t go down. What would happen to the <span class="math inline">\(R^2\)</span>? What would happen to the adjusted <span class="math inline">\(R^2\)</span>?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The unadjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; would stay the same and the adjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; would go down. Note that unadjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; never decreases by adding another predictor, it can only stay the same or increase. The adjusted &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; increases only if the addition of a predictor reduces the variance of the error larger than add one to &lt;span class="math inline"&gt;\(k\)&lt;/span&gt; in denominator.&lt;/p&gt;'><sup>111</sup></a></p>
</blockquote>
<p>Again, in a machine learning course, you will spend more time on how to select models. Using internal metrics of performance such as <span class="math inline">\(p\)</span>-values or adjusted <span class="math inline">\(R\)</span> squared are one way but using external measures of predictive performance such as <strong>cross validation</strong> or <strong>hold out</strong> sets will be introduced.</p>
</div>
<div id="reduced-model" class="section level3" number="29.3.5">
<h3>
<span class="header-section-number">29.3.5</span> Reduced model<a class="anchor" aria-label="anchor" href="#reduced-model"><i class="fas fa-link"></i></a>
</h3>
<p>Now let’s drop <code>duration</code> from the model and compare to our previous model:</p>
<div class="sourceCode" id="cb1013"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod_multi2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">+</span><span class="va">stock_photo</span><span class="op">+</span><span class="va">wheels</span>, data<span class="op">=</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<p>And the summary:</p>
<div class="sourceCode" id="cb1014"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod_multi2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond + stock_photo + wheels, data = mariokart_new)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.454  -2.959  -0.949   2.712  14.061 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     41.2245     1.4911  27.648  &lt; 2e-16 ***
## condused        -5.1763     0.9961  -5.196 7.21e-07 ***
## stock_photoyes   1.1177     1.0192   1.097    0.275    
## wheels           7.2984     0.5448  13.397  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.884 on 137 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7128 
## F-statistic: 116.8 on 3 and 137 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As a reminder, the previous model summary is:</p>
<div class="sourceCode" id="cb1016"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod_multi</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ ., data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.3788  -2.9854  -0.9654   2.6915  14.0346 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    41.34153    1.71167  24.153  &lt; 2e-16 ***
## condused       -5.13056    1.05112  -4.881 2.91e-06 ***
## stock_photoyes  1.08031    1.05682   1.022    0.308    
## duration       -0.02681    0.19041  -0.141    0.888    
## wheels          7.28518    0.55469  13.134  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.901 on 136 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7108 
## F-statistic: 87.01 on 4 and 136 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Notice that the adjusted <span class="math inline">\(R^2\)</span> improved by dropping <code>duration</code>. Finally, let’s drop <code>stock_photo</code>.</p>
<div class="sourceCode" id="cb1018"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mario_mod_multi3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">total_pr</span><span class="op">~</span><span class="va">cond</span><span class="op">+</span><span class="va">wheels</span>, data<span class="op">=</span><span class="va">mariokart_new</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb1019"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mario_mod_multi3</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond + wheels, data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0078  -3.0754  -0.8254   2.9822  14.1646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  42.3698     1.0651  39.780  &lt; 2e-16 ***
## condused     -5.5848     0.9245  -6.041 1.35e-08 ***
## wheels        7.2328     0.5419  13.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.887 on 138 degrees of freedom
## Multiple R-squared:  0.7165, Adjusted R-squared:  0.7124 
## F-statistic: 174.4 on 2 and 138 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Though the adjusted <span class="math inline">\(R^2\)</span> dropped a little, it is only in the fourth decimal place and thus essentially the same value. We therefore will go with this model.</p>
</div>
<div id="confidence-and-prediction-intervals" class="section level3" number="29.3.6">
<h3>
<span class="header-section-number">29.3.6</span> Confidence and prediction intervals<a class="anchor" aria-label="anchor" href="#confidence-and-prediction-intervals"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s suppose we want to predict the average total price for a Mario Kart sale with 2 wheels and in new condition. We can again use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function.</p>
<div class="sourceCode" id="cb1021"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mario_mod_multi3</span>,newdata<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cond<span class="op">=</span><span class="st">"new"</span>,wheels<span class="op">=</span><span class="fl">2</span><span class="op">)</span>,interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 56.83544 55.49789 58.17299</code></pre>
<p>We are 95% confident that the average price of a Mario Kart sale for a new item with 2 wheels will be between 55.50 and 58.17.</p>
<blockquote>
<p><strong>Exercise</strong>:
Find and interpret the prediction interval for a new Mario Kart with 2 wheels.</p>
</blockquote>
<div class="sourceCode" id="cb1023"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mario_mod_multi3</span>,newdata<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cond<span class="op">=</span><span class="st">"new"</span>,wheels<span class="op">=</span><span class="fl">2</span><span class="op">)</span>,interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 56.83544 47.07941 66.59147</code></pre>
<p>We are 95% confident that the price of a Mario Kart sale for a new item with 2 wheels will be between 47.07 and 66.59.</p>
</div>
<div id="diagnostics" class="section level3" number="29.3.7">
<h3>
<span class="header-section-number">29.3.7</span> Diagnostics<a class="anchor" aria-label="anchor" href="#diagnostics"><i class="fas fa-link"></i></a>
</h3>
<p>The diagnostics for the model are similar to what we did in a previous chapter. Nothing in these plots gives us concern; however, there is one leverage point, Figure <a href="LRMULTI.html#fig:diag305-fig">29.7</a>.</p>
<div class="sourceCode" id="cb1025"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mario_mod_multi3</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:diag305-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/diag305-fig-1.png" alt="Diagnostic residual plots for multiple regression model." width="50%"><img src="31-Multiple-Linear-Regression_files/figure-html/diag305-fig-2.png" alt="Diagnostic residual plots for multiple regression model." width="50%"><img src="31-Multiple-Linear-Regression_files/figure-html/diag305-fig-3.png" alt="Diagnostic residual plots for multiple regression model." width="50%"><img src="31-Multiple-Linear-Regression_files/figure-html/diag305-fig-4.png" alt="Diagnostic residual plots for multiple regression model." width="50%"><p class="caption">
Figure 29.7: Diagnostic residual plots for multiple regression model.
</p>
</div>
</div>
</div>
<div id="interaction-and-higher-order-terms" class="section level2" number="29.4">
<h2>
<span class="header-section-number">29.4</span> Interaction and Higher Order Terms<a class="anchor" aria-label="anchor" href="#interaction-and-higher-order-terms"><i class="fas fa-link"></i></a>
</h2>
<p>As a final short topic we want to explore <strong>feature engineering</strong>. Thus far we have not done any transformation to the predictors in the data set except maybe making categorical variables into factors. In data analysis competitions, such as Kaggle, feature engineering is often one of the most important steps. In a machine learning course, you will look at different tools but in this book we will look at simple transformations such as higher order terms and interactions.</p>
<p>To make this section more relevant, we are going to switch to a different data set. Load the library <strong>ISLR</strong>.</p>
<div class="sourceCode" id="cb1026"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.statlearning.com">ISLR</a></span><span class="op">)</span></span></code></pre></div>
<p>The data set of interest is <code>Credit</code>. Use the help menu to read about the variables. This is a simulated data set of credit card debt.</p>
<div class="sourceCode" id="cb1027"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="va">Credit</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Rows: 400
## Columns: 12
## $ ID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~
## $ Income    &lt;dbl&gt; 14.891, 106.025, 104.593, 148.924, 55.882, 80.180, 20.996, 7~
## $ Limit     &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6819, ~
## $ Rating    &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 138, ~
## $ Cards     &lt;int&gt; 2, 3, 4, 3, 2, 4, 2, 2, 5, 3, 4, 3, 1, 1, 2, 3, 3, 3, 1, 2, ~
## $ Age       &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, 75, ~
## $ Education &lt;int&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13, 15,~
## $ Gender    &lt;fct&gt;  Male, Female,  Male, Female,  Male,  Male, Female,  Male, F~
## $ Student   &lt;fct&gt; No, Yes, No, No, No, No, No, No, No, Yes, No, No, No, No, No~
## $ Married   &lt;fct&gt; Yes, Yes, No, No, Yes, No, No, No, No, Yes, Yes, No, Yes, Ye~
## $ Ethnicity &lt;fct&gt; Caucasian, Asian, Asian, Asian, Caucasian, Caucasian, Africa~
## $ Balance   &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407, 0,~</code></pre>
<p>Notice that <code>ID</code> is being treated as an integer. We could change it to a character since it is a label, but for our work in this chapter we will not bother.</p>
<p>Suppose we suspected that there is a relationship between <code>Balance</code>, the response, and the predictors <code>Income</code> and <code>Student</code>. Note: we actually are using this model for educational purposes and did not go through a model selection process.</p>
<p>The first model simply has these predictors in the model.</p>
<div class="sourceCode" id="cb1029"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_mod1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span><span class="op">+</span><span class="va">Student</span>,data<span class="op">=</span><span class="va">Credit</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb1030"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">credit_mod1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income + Student, data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -762.37 -331.38  -45.04  323.60  818.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 211.1430    32.4572   6.505 2.34e-10 ***
## Income        5.9843     0.5566  10.751  &lt; 2e-16 ***
## StudentYes  382.6705    65.3108   5.859 9.78e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 391.8 on 397 degrees of freedom
## Multiple R-squared:  0.2775, Adjusted R-squared:  0.2738 
## F-statistic: 76.22 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Let’s plot the data and the regression line. The impact of putting in the categorical variable <code>Student</code> is to just shift the intercept. The slope remains the same, Figure <a href="LRMULTI.html#fig:scat305-fig">29.8</a>.</p>
<div class="sourceCode" id="cb1032"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_line</span><span class="op">(</span><span class="va">.fitted</span><span class="op">~</span><span class="va">Income</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod1</span><span class="op">)</span>, <span class="va">Student</span> <span class="op">==</span> <span class="st">"Yes"</span><span class="op">)</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span><span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_line</span><span class="op">(</span><span class="va">.fitted</span><span class="op">~</span><span class="va">Income</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod1</span><span class="op">)</span>, <span class="va">Student</span> <span class="op">==</span> <span class="st">"No"</span><span class="op">)</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat305-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/scat305-fig-1.png" alt="Scatterplot of credit card balance for income and student status." width="672"><p class="caption">
Figure 29.8: Scatterplot of credit card balance for income and student status.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br>
Write the equation for the regression model.</p>
</blockquote>
<p><span class="math display">\[
\mbox{E}(Balance)=\beta_0 + \beta_1*\text{Income}+ \beta_2*\text{(Student=Yes)}
\]</span></p>
<p>or</p>
<p><span class="math display">\[
\mbox{E}(Balance)=211.14 + 5.98*\text{Income}+ 382.67*\text{(Student=Yes)}
\]</span></p>
<p>If the observation is a student, then the intercept is increased by 382.67.</p>
<p>In this next case, we would want to include an interaction term in the model: an <strong>interaction</strong> term allows the slope to change as well. To include an interaction term when building a model in <code>R</code>, we use <code>*</code>.</p>
<div class="sourceCode" id="cb1033"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_mod2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span><span class="op">*</span><span class="va">Student</span>,data<span class="op">=</span><span class="va">Credit</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb1034"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">credit_mod2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income * Student, data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -773.39 -325.70  -41.13  321.65  814.04 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       200.6232    33.6984   5.953 5.79e-09 ***
## Income              6.2182     0.5921  10.502  &lt; 2e-16 ***
## StudentYes        476.6758   104.3512   4.568 6.59e-06 ***
## Income:StudentYes  -1.9992     1.7313  -1.155    0.249    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 391.6 on 396 degrees of freedom
## Multiple R-squared:  0.2799, Adjusted R-squared:  0.2744 
## F-statistic:  51.3 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1036"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod2</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_line</span><span class="op">(</span><span class="va">.fitted</span><span class="op">~</span><span class="va">Income</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod2</span><span class="op">)</span>, <span class="va">Student</span> <span class="op">==</span> <span class="st">"Yes"</span><span class="op">)</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span><span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_line</span><span class="op">(</span><span class="va">.fitted</span><span class="op">~</span><span class="va">Income</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod2</span><span class="op">)</span>, <span class="va">Student</span> <span class="op">==</span> <span class="st">"No"</span><span class="op">)</span>,color<span class="op">=</span><span class="op">~</span><span class="va">Student</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat306-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/scat306-fig-1.png" alt="Scatterplot of credit card balance for income and student status with an interaction term." width="672"><p class="caption">
Figure 29.9: Scatterplot of credit card balance for income and student status with an interaction term.
</p>
</div>
<p>Now we have a different slope and intercept for each case of the <code>Student</code> variable, Figure <a href="LRMULTI.html#fig:scat306-fig">29.9</a>. Thus there is a synergy or interaction between these variables. The student status changes the impact of <code>Income</code> on <code>Balance</code>. If you are a student, then for every increase in income of 1 the balance increase by 4.219 on average. If you are not a student, every increase in income of 1 increases the average balance by 6.2182.</p>
<p>Furthermore, if you suspect that perhaps a curved relationship exists between two variables, we could include a higher order term. As an example, let’s add a quadratic term for <code>Income</code> to our model (without the interaction). To do this in <code>R</code>, we need to wrap the higher order term in <code><a href="https://rdrr.io/r/base/AsIs.html">I()</a></code>. If we include a higher order term, we usually want to include the lower order terms as well; a better approach is to make the decision on what to include using predictive performance.</p>
<div class="sourceCode" id="cb1037"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_mod3</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">Income</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,data<span class="op">=</span><span class="va">Credit</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb1038"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">credit_mod3</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income + I(Income^2), data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -782.88 -361.40  -54.98  316.26 1104.39 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 285.3973    54.1720   5.268 2.26e-07 ***
## Income        4.3972     1.9078   2.305   0.0217 *  
## I(Income^2)   0.0109     0.0120   0.908   0.3642    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 408 on 397 degrees of freedom
## Multiple R-squared:  0.2166, Adjusted R-squared:  0.2127 
## F-statistic: 54.88 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1040"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">credit_mod3</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">Balance</span><span class="op">~</span><span class="va">Income</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_line</span><span class="op">(</span><span class="va">.fitted</span><span class="op">~</span><span class="va">Income</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat307-fig"></span>
<img src="31-Multiple-Linear-Regression_files/figure-html/scat307-fig-1.png" alt="Scatterplot of credit card balance for income with a quadratic fit." width="672"><p class="caption">
Figure 29.10: Scatterplot of credit card balance for income with a quadratic fit.
</p>
</div>
<p>There is not much of a quadratic relationship, Figure <a href="LRMULTI.html#fig:scat307-fig">29.10</a>.</p>
<div id="summary-3" class="section level3" number="29.4.1">
<h3>
<span class="header-section-number">29.4.1</span> Summary<a class="anchor" aria-label="anchor" href="#summary-3"><i class="fas fa-link"></i></a>
</h3>
<p>In this chapter we have extended the linear regression model by allowing multiple predictors. This allows us to account for confounding variables and make more sophisticated models. The interpretation and evaluation of the model changes.</p>
</div>
</div>
<div id="homework-problems-28" class="section level2" number="29.5">
<h2>
<span class="header-section-number">29.5</span> Homework Problems<a class="anchor" aria-label="anchor" href="#homework-problems-28"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>The <code>mtcars</code> data set contains average mileage (mpg) and other information about specific makes and models of cars. (This data set is built-in to <code>R</code>; for more information about this data set, reference the documentation with <code><a href="https://rdrr.io/r/datasets/mtcars.html">?mtcars</a></code>).</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Build and interpret the coefficients of a model fitting <code>mpg</code> against displacement (<code>disp</code>), horsepower (<code>hp</code>), rear axle ratio (<code>drat</code>), and weight in 1000 lbs (<code>wt</code>).<br>
</li>
<li>Given your model, what is the expected mpg for a vehicle with a displacement of 170, a horsepower of 100, a <code>drat</code> of 3.80 and a wt of 2,900 lbs. Construct a 95% confidence interval and prediction interval for that expected mpg.<br>
</li>
<li>Repeat part (b) with a bootstrap for the confidence interval.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Is that the best model for predicting mpg? Try a variety of different models. You could explore higher order terms or even interactions. One place to start is by using the <code><a href="https://rdrr.io/r/graphics/pairs.html">pairs()</a></code> function on <code>mtcars</code> to plot a large pairwise scatterplot. How high could you get adjusted <span class="math inline">\(R\)</span>-squared? Keep in mind that is only one measure of fit.</li>
</ol>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="LRSIM.html"><span class="header-section-number">28</span> Simulation-Based Linear Regression</a></div>
<div class="next"><a href="LOGREG.html"><span class="header-section-number">30</span> Logistic Regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#LRMULTI"><span class="header-section-number">29</span> Multiple Linear Regression</a></li>
<li><a class="nav-link" href="#objectives-29"><span class="header-section-number">29.1</span> Objectives</a></li>
<li><a class="nav-link" href="#introduction-to-multiple-regression"><span class="header-section-number">29.2</span> Introduction to multiple regression</a></li>
<li>
<a class="nav-link" href="#multiple-regression"><span class="header-section-number">29.3</span> Multiple regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-single-variable-model-for-the-mario-kart-data"><span class="header-section-number">29.3.1</span> A single-variable model for the Mario Kart data</a></li>
<li><a class="nav-link" href="#including-and-assessing-many-variables-in-a-model"><span class="header-section-number">29.3.2</span> Including and assessing many variables in a model</a></li>
<li><a class="nav-link" href="#inference-1"><span class="header-section-number">29.3.3</span> Inference</a></li>
<li><a class="nav-link" href="#adjusted-r2-as-a-better-estimate-of-explained-variance"><span class="header-section-number">29.3.4</span> Adjusted \(R^2\) as a better estimate of explained variance</a></li>
<li><a class="nav-link" href="#reduced-model"><span class="header-section-number">29.3.5</span> Reduced model</a></li>
<li><a class="nav-link" href="#confidence-and-prediction-intervals"><span class="header-section-number">29.3.6</span> Confidence and prediction intervals</a></li>
<li><a class="nav-link" href="#diagnostics"><span class="header-section-number">29.3.7</span> Diagnostics</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#interaction-and-higher-order-terms"><span class="header-section-number">29.4</span> Interaction and Higher Order Terms</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#summary-3"><span class="header-section-number">29.4.1</span> Summary</a></li></ul>
</li>
<li><a class="nav-link" href="#homework-problems-28"><span class="header-section-number">29.5</span> Homework Problems</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/blob/master/31-Multiple-Linear-Regression.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/edit/master/31-Multiple-Linear-Regression.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Probability and Statistics for Scientists and Engineers</strong>" was written by Matthew Davis, Brianna Hitt, Ken Horton, Kris Pruitt, Bradley Warner. It was last built on 2022-07-21.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
