<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 28 Linear Regression Inference | Computational Probability and Statistics - MASTER</title>
<meta name="author" content="Matthew Davis">
<meta name="author" content="Brianna Hitt">
<meta name="author" content="Ken Horton">
<meta name="author" content="Kris Pruitt">
<meta name="author" content="Bradley Warner">
<meta name="description" content="28.1 Objectives Given a simple linear regression model, conduct inference on the coefficients \(\beta_0\) and \(\beta_1\). Given a simple linear regression model, calculate the predicted response...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 28 Linear Regression Inference | Computational Probability and Statistics - MASTER">
<meta property="og:type" content="book">
<meta property="og:image" content="/figures/Cover_Majors.png">
<meta property="og:description" content="28.1 Objectives Given a simple linear regression model, conduct inference on the coefficients \(\beta_0\) and \(\beta_1\). Given a simple linear regression model, calculate the predicted response...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 28 Linear Regression Inference | Computational Probability and Statistics - MASTER">
<meta name="twitter:description" content="28.1 Objectives Given a simple linear regression model, conduct inference on the coefficients \(\beta_0\) and \(\beta_1\). Given a simple linear regression model, calculate the predicted response...">
<meta name="twitter:image" content="/figures/Cover_Majors.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Probability and Statistics - MASTER</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="objectives.html">Objectives</a></li>
<li class="book-part">Descriptive Statistical Modeling</li>
<li><a class="" href="CS1.html"><span class="header-section-number">1</span> Data Case Study</a></li>
<li><a class="" href="DB.html"><span class="header-section-number">2</span> Data Basics</a></li>
<li><a class="" href="ODCP.html"><span class="header-section-number">3</span> Overview of Data Collection Principles</a></li>
<li><a class="" href="STUDY.html"><span class="header-section-number">4</span> Studies</a></li>
<li><a class="" href="NUMDATA.html"><span class="header-section-number">5</span> Numerical Data</a></li>
<li><a class="" href="CATDATA.html"><span class="header-section-number">6</span> Categorical Data</a></li>
<li class="book-part">Probability Modeling</li>
<li><a class="" href="CS2.html"><span class="header-section-number">7</span> Probability Case Study</a></li>
<li><a class="" href="PROBRULES.html"><span class="header-section-number">8</span> Probability Rules</a></li>
<li><a class="" href="CONDPROB.html"><span class="header-section-number">9</span> Conditional Probability</a></li>
<li><a class="" href="RANDVAR.html"><span class="header-section-number">10</span> Random Variables</a></li>
<li><a class="" href="CONRANDVAR.html"><span class="header-section-number">11</span> Continuous Random Variables</a></li>
<li><a class="" href="DISCRETENAMED.html"><span class="header-section-number">12</span> Named Discrete Distributions</a></li>
<li><a class="" href="CONTNNAMED.html"><span class="header-section-number">13</span> Named Continuous Distributions</a></li>
<li><a class="" href="MULTIDISTS.html"><span class="header-section-number">14</span> Multivariate Distributions</a></li>
<li><a class="" href="MULTIEXP.html"><span class="header-section-number">15</span> Multivariate Expectation</a></li>
<li><a class="" href="TRANS.html"><span class="header-section-number">16</span> Transformations</a></li>
<li><a class="" href="EST.html"><span class="header-section-number">17</span> Estimation Methods</a></li>
<li class="book-part">Inferential Statistical Modeling</li>
<li><a class="" href="CS3.html"><span class="header-section-number">18</span> Hypothesis Testing Case Study</a></li>
<li><a class="" href="HYPTESTSIM.html"><span class="header-section-number">19</span> Hypothesis Testing with Simulation</a></li>
<li><a class="" href="HYPTESTDIST.html"><span class="header-section-number">20</span> Hypothesis Testing with Known Distributions</a></li>
<li><a class="" href="HYPTESTCLT.html"><span class="header-section-number">21</span> Hypothesis Testing with the Central Limit Theorem</a></li>
<li><a class="" href="ADDTESTS.html"><span class="header-section-number">22</span> Additional Hypothesis Tests</a></li>
<li><a class="" href="ANOVA.html"><span class="header-section-number">23</span> Analysis of Variance</a></li>
<li><a class="" href="CI.html"><span class="header-section-number">24</span> Confidence Intervals</a></li>
<li><a class="" href="BOOT.html"><span class="header-section-number">25</span> Bootstrap</a></li>
<li class="book-part">Predictive Statistical Modeling</li>
<li><a class="" href="CS4.html"><span class="header-section-number">26</span> Linear Regression Case Study</a></li>
<li><a class="" href="LRBASICS.html"><span class="header-section-number">27</span> Linear Regression Basics</a></li>
<li><a class="active" href="LRINF.html"><span class="header-section-number">28</span> Linear Regression Inference</a></li>
<li><a class="" href="LRDIAG.html"><span class="header-section-number">29</span> Regression Diagnostics</a></li>
<li><a class="" href="LRSIM.html"><span class="header-section-number">30</span> Simulation-Based Linear Regression</a></li>
<li><a class="" href="LRMULTI.html"><span class="header-section-number">31</span> Multiple Linear Regression</a></li>
<li><a class="" href="LOGREG.html"><span class="header-section-number">32</span> Logistic Regression</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="LRINF" class="section level1" number="28">
<h1>
<span class="header-section-number">28</span> Linear Regression Inference<a class="anchor" aria-label="anchor" href="#LRINF"><i class="fas fa-link"></i></a>
</h1>
<div id="objectives-28" class="section level2" number="28.1">
<h2>
<span class="header-section-number">28.1</span> Objectives<a class="anchor" aria-label="anchor" href="#objectives-28"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Given a simple linear regression model, conduct inference on the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>Given a simple linear regression model, calculate the predicted response for a given value of the predictor.</p></li>
<li><p>Build and interpret confidence and prediction intervals for values of the response variable.</p></li>
</ol>
</div>
<div id="introduction-4" class="section level2" number="28.2">
<h2>
<span class="header-section-number">28.2</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-4"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter we discuss uncertainty in the estimates of the slope and y-intercept for a regression line. This will allow us to perform inference and predictions. Just as we identified standard errors for point estimates in previous chapters, we first discuss standard errors for these new estimates. This chapter is a classical chapter in the sense that we will be using the normal distribution. We will assume that the errors are normally distributed with constant variance. Later in the book, we will relax these assumptions.</p>
<div id="regression" class="section level3" number="28.2.1">
<h3>
<span class="header-section-number">28.2.1</span> Regression<a class="anchor" aria-label="anchor" href="#regression"><i class="fas fa-link"></i></a>
</h3>
<p>Last chapter, we introduced linear models using the simple linear regression model:
<span class="math display">\[
Y=\beta_0+\beta_1X+e
\]</span></p>
<p>where now we assume the error term follows a normal distribution with mean 0 and constant standard deviation <span class="math inline">\(\sigma\)</span>. Using the method of least squares, which does not require the assumption of normality, we obtain estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[
\hat{\beta}_1 = {\sum x_i y_i - n\bar{x}\bar{y} \over \sum x_i^2 -n\bar{x}^2}
\]</span>
<span class="math display">\[
\hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x}
\]</span></p>
<p>If we assume a probability distribution for the errors, we could also find point estimates using maximum likelihood methods. This will not be discussed in this book.</p>
<p>Using these estimates, for a given value of the predictor, <span class="math inline">\(x_*\)</span>, we can obtain a prediction of the response variable. Here we are using the subscript <span class="math inline">\(_*\)</span> to denote a new value for the explanatory variable. The resulting prediction, which we will denote <span class="math inline">\(\hat{Y}_*\)</span>, is the <strong>average</strong> or <strong>expected value</strong> of the response given predictor value <span class="math inline">\(x_*\)</span>:</p>
<p><span class="math display">\[
\hat{Y}_*=\hat{\beta}_0+\hat{\beta}_1x_*
\]</span></p>
<p>The reason this model returns the expected value of the response at the given value of the predictor is because the error term has an expected value of zero. As a review of the properties of expectation as well as last chapter, we have:</p>
<p><span class="math display">\[
E(Y|X=x)=E(\beta_0+\beta_1x+e)=Y=\beta_0+\beta_1x+E(e)=\beta_0+\beta_1x
\]</span>
because <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(x\)</span> are constants.</p>
<p>It should be abundantly clear by now that <span class="math inline">\(\hat{Y}_*\)</span>, <span class="math inline">\(\hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> are <strong><em>estimators</em></strong>. Being estimators, they are dependent on our random sample, our data. If we collect a new random sample from the same population, we will get new estimates from these estimators. Thus, we can think of <span class="math inline">\(\hat{Y}_*\)</span>, <span class="math inline">\(\hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> as <strong>random variables</strong>. Like all random variables, they have distributions. We can use the distribution of an estimator to build confidence intervals and conduct hypothesis tests about the true values of the parameter it is intended to estimate. The estimators based on least squares are unbiased, their distributions are centered around the actual values of <span class="math inline">\(Y\)</span>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively.</p>
</div>
<div id="review-of-assumptions" class="section level3" number="28.2.2">
<h3>
<span class="header-section-number">28.2.2</span> Review of assumptions<a class="anchor" aria-label="anchor" href="#review-of-assumptions"><i class="fas fa-link"></i></a>
</h3>
<p>We will review the assumptions of the least squares model because they are important for inference. Refer to Figure <a href="LRINF.html#fig:assump271-fig">28.1</a>, which plots the linear regression in the top row and the residuals in the second row. We generally assume the following:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Fit</strong>. The data should show a linear trend. If there is a nonlinear trend, a transformation of the explanatory variable or a more advanced regression method should be applied. When looking at the residual plot, if the trend is linear, we should see a spread of points that are flat. The left column of Figure <a href="LRINF.html#fig:assump271-fig">28.1</a> is an example of a nonlinear relationship. The top plot is the regression plot and we can see what looks like a quadratic relationship instead of a linear one. The residual plot, the plot in the lower left corner of Figure <a href="LRINF.html#fig:assump271-fig">28.1</a>, also exhibits this non-linear trend.<br>
</li>
<li>
<strong>Nearly normal residuals</strong>. Generally the residuals must be nearly normal to use a <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> for inference. When this assumption is found to be unreasonable, it is usually because of <strong>outliers</strong> or concerns about <strong>influential</strong> points. An example of non-normal residuals is shown in the second column of Figure <a href="LRINF.html#fig:assump271-fig">28.1</a>. A <strong>qq</strong> plot is also useful as a diagnostic tool as we have seen. We can still use the <strong>bootstrap</strong> as an inference tool if the normality assumption is unreasonable.<br>
</li>
<li>
<strong>Constant variability</strong>. The variability of points around the least squares line remains roughly constant. An example of non-constant variability is shown in the third panel of Figure <a href="LRINF.html#fig:assump271-fig">28.1</a>. The constant variability assumption is needed for the <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions. It is not required for the bootstrap method.<br>
</li>
<li>
<strong>Independent observations</strong>. Be cautious about applying regression to data collected sequentially in what is called a <strong>time series</strong>. Such data may have an underlying structure that should be considered in a model and analysis. An example of a time series where independence is violated is shown in the fourth panel of Figure <a href="LRINF.html#fig:assump271-fig">28.1</a>. More advanced methods are required for time series data even including using a bootstrap.</li>
</ol>
<p>In a later chapter we will explore more regression diagnostics.</p>
<div class="figure">
<span style="display:block;" id="fig:assump271-fig"></span>
<img src="28-Linear-Regression-Inference_files/figure-html/assump271-fig-1.png" alt="Plots of linear regression and residual to illustrate the assumptions of the model." width="672"><p class="caption">
Figure 28.1: Plots of linear regression and residual to illustrate the assumptions of the model.
</p>
</div>
</div>
<div id="distribution-of-our-estimators" class="section level3" number="28.2.3">
<h3>
<span class="header-section-number">28.2.3</span> Distribution of our estimators<a class="anchor" aria-label="anchor" href="#distribution-of-our-estimators"><i class="fas fa-link"></i></a>
</h3>
<p>With the assumption that the error term is normally distributed, we can find the distributions of our estimates, which turn out to be normal:</p>
<p><span class="math display">\[
\hat{\beta}_0\sim N\left(\beta_0, \sigma\sqrt{{1\over n}+{\bar{x}^2\over \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_1\sim N\left(\beta_1, {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p><span class="math display">\[
\hat{Y}_* \sim N\left(\beta_0+\beta_1x_*, \sigma\sqrt{{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p>Notice that all three of these are unbiased, the expected value is equal to the parameter being estimated. Looking at the variance of the slope estimate we can see that is a function of the underlying unexplained variance, <span class="math inline">\(\sigma^2\)</span> and the data. The denominator is increased by having a larger spread in the explanatory variable. The slope of the estimated line is more stable, less variable, if the independent variable has high variance. That is interesting. If you are designing an experiment, this gives you insight in how to select the range of values for your explanatory variable.</p>
</div>
</div>
<div id="inference" class="section level2" number="28.3">
<h2>
<span class="header-section-number">28.3</span> Inference<a class="anchor" aria-label="anchor" href="#inference"><i class="fas fa-link"></i></a>
</h2>
<p>Now that we know how the coefficient estimates and the average predicted values behave, we can perform inference on their true values. Let’s take <span class="math inline">\(\hat{\beta}_1\)</span> for demonstration:</p>
<p><span class="math display">\[
\hat{\beta}_1\sim N\left(\beta_1, {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta_1 \over {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\sim N\left(0, 1\right)
\]</span></p>
<p>However, note that the expression on the left depends on error standard deviation, <span class="math inline">\(\sigma\)</span>. In reality, we will not know this value and will have to estimate it with</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{{1\over n-2} \sum_{i=1}^n \hat{e}_i^2}
\]</span></p>
<p>where <span class="math inline">\(\hat{e}_i\)</span> is the observed <span class="math inline">\(i\)</span>th <strong>residual</strong> (<span class="math inline">\(\hat{e}_i=y_i-\hat{\beta}_0-\hat{\beta}_1x_i\)</span>).</p>
<p>As we learned in the last block, if we replace population standard deviation (<span class="math inline">\(\sigma\)</span>) with an estimation, the resulting random variable no longer has the standard normal distribution. In fact, it can be shown that</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\sim \textsf{t}\left(n-2\right)
\]</span>
We only have <span class="math inline">\(n-2\)</span> degrees of freedom because in the estimation of <span class="math inline">\(\sigma^2\)</span> we had to estimate two parameters, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>We can use this information to build a <span class="math inline">\((1-\alpha)*100\%\)</span> confidence interval for <span class="math inline">\(\beta_1\)</span>. First, we recognize that</p>
<p><span class="math display">\[
\mbox{P}\left(-t_{\alpha/2,n-2} \leq {\hat{\beta}_1-\beta_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\leq t_{\alpha/2,n-2} \right) = 1-\alpha
\]</span></p>
<p>Solving the expression inside the probability statement for <span class="math inline">\(\beta_1\)</span> yields a confidence interval of</p>
<p><span class="math display">\[
\beta_1 \in \left(\hat{\beta_1} \pm t_{\alpha/2,n-2}{\hat \sigma \over \sqrt{\sum(x_i-\bar{x})^2}}\right)
\]</span></p>
<p>We can also evaluate the null hypothesis <span class="math inline">\(H_0: \beta_1 =\beta^*_1\)</span>. If the true value of <span class="math inline">\(\beta_1\)</span> were <span class="math inline">\(\beta^*_1\)</span>, then the estimated <span class="math inline">\(\hat{\beta_1}\)</span> should be around that value. In fact, if <span class="math inline">\(H_0\)</span> were true, the value</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta^*_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}
\]</span></p>
<p>has the <span class="math inline">\(\textsf{t}\)</span> distribution with <span class="math inline">\(n-2\)</span> degrees of freedom. Thus, once we collect a sample and obtain the observed <span class="math inline">\(\hat{\beta_1}\)</span> and <span class="math inline">\(\hat \sigma\)</span>, we can calculate this quantity and determine whether it is far enough from zero to reject <span class="math inline">\(H_0\)</span>.</p>
<p>Similarly, we can use the distribution of <span class="math inline">\(\hat \beta_0\)</span> to build a confidence interval or conduct a hypothesis test on <span class="math inline">\(\beta_0\)</span>, but we usually don’t. This has to do with the interpretation of <span class="math inline">\(\beta_0\)</span>.</p>
<div id="starbucks" class="section level3" number="28.3.1">
<h3>
<span class="header-section-number">28.3.1</span> Starbucks<a class="anchor" aria-label="anchor" href="#starbucks"><i class="fas fa-link"></i></a>
</h3>
<p>That was a great deal of mathematics and theory. Let’s put it to use on the example from Starbucks. In the file <code>data/starbucks.csv</code> we have nutritional facts for several Starbucks’ food items. We used this data in the homework for last chapter. We will use this data again to illustrate the ideas we have introduced in this section.</p>
<p>Read in the data.</p>
<div class="sourceCode" id="cb879"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">starbucks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/starbucks.csv"</span><span class="op">)</span>  <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">type</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p><strong>Exercise</strong>:<br>
Summarize and explore the data.</p>
</blockquote>
<p>Let’s look at a summary of the data.</p>
<div class="sourceCode" id="cb880"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="va">starbucks</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Rows: 77
## Columns: 7
## $ item     &lt;chr&gt; "8-Grain Roll", "Apple Bran Muffin", "Apple Fritter", "Banana~
## $ calories &lt;dbl&gt; 350, 350, 420, 490, 130, 370, 460, 370, 310, 420, 380, 320, 3~
## $ fat      &lt;dbl&gt; 8, 9, 20, 19, 6, 14, 22, 14, 18, 25, 17, 12, 17, 21, 5, 18, 1~
## $ carb     &lt;dbl&gt; 67, 64, 59, 75, 17, 47, 61, 55, 32, 39, 51, 53, 34, 57, 52, 7~
## $ fiber    &lt;dbl&gt; 5, 7, 0, 4, 0, 5, 2, 0, 0, 0, 2, 3, 2, 2, 3, 3, 2, 3, 0, 2, 0~
## $ protein  &lt;dbl&gt; 10, 6, 5, 7, 0, 6, 7, 6, 5, 7, 4, 6, 5, 5, 12, 7, 8, 6, 0, 10~
## $ type     &lt;fct&gt; bakery, bakery, bakery, bakery, bakery, bakery, bakery, baker~</code></pre>
<div class="sourceCode" id="cb882"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mosaicCore/man/inspect.html">inspect</a></span><span class="op">(</span><span class="va">starbucks</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## categorical variables:  
##   name     class levels  n missing
## 1 item character     77 77       0
## 2 type    factor      7 77       0
##                                    distribution
## 1 8-Grain Roll (1.3%) ...                      
## 2 bakery (53.2%), petite (11.7%) ...           
## 
## quantitative variables:  
##       name   class min  Q1 median  Q3 max       mean         sd  n missing
## 1 calories numeric  80 300    350 420 500 338.831169 105.368701 77       0
## 2      fat numeric   0   9     13  18  28  13.766234   7.095488 77       0
## 3     carb numeric  16  31     45  59  80  44.870130  16.551634 77       0
## 4    fiber numeric   0   0      2   4   7   2.220779   2.112764 77       0
## 5  protein numeric   0   5      7  15  34   9.480519   8.079556 77       0</code></pre>
<p>Let’s predict calories from the carbohydrate content.</p>
<blockquote>
<p><strong>Exercise</strong>:<br>
Create a scatterplot of calories and carbohydrate, carbs, content.</p>
</blockquote>
<p>Figure <a href="LRINF.html#fig:scat271-fig">28.2</a> is the scatterplot.</p>
<div class="sourceCode" id="cb884"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">starbucks</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">calories</span><span class="op">~</span><span class="va">carb</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>x<span class="op">=</span><span class="st">"Carbohydrates"</span>,y<span class="op">=</span><span class="st">"Calories"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:scat271-fig"></span>
<img src="28-Linear-Regression-Inference_files/figure-html/scat271-fig-1.png" alt="Scatterplot of calories and carbohydrate content in Starbucks' products." width="672"><p class="caption">
Figure 28.2: Scatterplot of calories and carbohydrate content in Starbucks’ products.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br>
Use <code>R</code> to fit a linear regression model by regressing <code>calories</code> on <code>carb</code>.</p>
</blockquote>
<p>The results of fitting a linear least squares model is stored in the <code>star_mod</code> object.</p>
<div class="sourceCode" id="cb885"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">star_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">calories</span> <span class="op">~</span> <span class="va">carb</span>, data <span class="op">=</span> <span class="va">starbucks</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb886"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">star_mod</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = calories ~ carb, data = starbucks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -151.962  -70.556   -0.636   54.908  179.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 146.0204    25.9186   5.634 2.93e-07 ***
## carb          4.2971     0.5424   7.923 1.67e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 78.26 on 75 degrees of freedom
## Multiple R-squared:  0.4556, Adjusted R-squared:  0.4484 
## F-statistic: 62.77 on 1 and 75 DF,  p-value: 1.673e-11</code></pre>
<div id="hypothesis-test" class="section level4" number="28.3.1.1">
<h4>
<span class="header-section-number">28.3.1.1</span> Hypothesis test<a class="anchor" aria-label="anchor" href="#hypothesis-test"><i class="fas fa-link"></i></a>
</h4>
<p>In the second row of the <strong>Coefficients</strong> portion of the table we have our point estimate, standard error, test statistic, and <span class="math inline">\(p\)</span>-value for the slope.</p>
<p>The hypotheses for this output is<br><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_1 = 0\)</span>. The true linear model has slope zero. The carb content has no impact on the the calorie content.<br><span class="math inline">\(H_A\)</span>: <span class="math inline">\(\beta_1 \neq 0\)</span>. The true linear model has a slope different than zero. The higher the carb content, the greater the average calorie content or vice-versa.</p>
<p>Our estimate of the slope is 4.297 with a standard error of 0.5424. Just for demonstration purposes, we will use <code>R</code> to calculate the test statistic and <span class="math inline">\(p\)</span>-value as a series of steps. The test statistic under the null hypothesis is:</p>
<p><span class="math display">\[
{\hat{\beta}_1-0 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}
\]</span>
The denominator is the standard error of the estimate. The estimate of the residual standard deviation is reported in the last line as 78.26. But it is just the square root of the sum of squared residuals divided by the degrees of freedom.</p>
<div class="sourceCode" id="cb888"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sighat</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">star_mod</span><span class="op">$</span><span class="va">residuals</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">/</span><span class="fl">75</span><span class="op">)</span></span>
<span><span class="va">sighat</span></span></code></pre></div>
<pre><code>## [1] 78.25956</code></pre>
<p>The standard error of the slope estimate is, and confirmed in the table:</p>
<div class="sourceCode" id="cb890"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">std_er</span><span class="op">&lt;-</span><span class="va">sighat</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/aggregating.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">starbucks</span><span class="op">$</span><span class="va">carb</span><span class="op">-</span><span class="fu">mean</span><span class="op">(</span><span class="va">starbucks</span><span class="op">$</span><span class="va">carb</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">std_er</span></span></code></pre></div>
<pre><code>## [1] 0.5423626</code></pre>
<p>The test statistic is</p>
<div class="sourceCode" id="cb892"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">4.2971</span><span class="op">-</span><span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="va">std_er</span></span></code></pre></div>
<pre><code>## [1] 7.922928</code></pre>
<p>And the <span class="math inline">\(p\)</span>-value</p>
<div class="sourceCode" id="cb894"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="op">(</span><span class="fl">4.2971</span><span class="op">-</span><span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="va">std_er</span>,<span class="fl">73</span>,lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 1.965319e-11</code></pre>
<p>This is slightly different from the table value because of the precision of the computer and the small <span class="math inline">\(p\)</span>-value.</p>
<p>We reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span> because the data provide strong evidence that the true slope parameter is greater than zero.</p>
<p>The computer software uses zero in the null hypothesis, if you wanted to test another value of the slope then you would have to do the calculations step by step like we did above.</p>
<p>By the way, this was not a <code>tidy</code> way to do the calculation. The <strong>broom</strong> package makes it easier to use <code>tidy</code> ideas on the regression model. We used these ideas in the last chapter.</p>
<p>As a reminder:</p>
<div class="sourceCode" id="cb896"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb897"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">star_mod</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   146.      25.9        5.63 2.93e- 7
## 2 carb            4.30     0.542      7.92 1.67e-11</code></pre>
<p>And step by step:</p>
<div class="sourceCode" id="cb899"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">star_mod</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">term</span><span class="op">==</span><span class="st">"carb"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>test_stat<span class="op">=</span><span class="op">(</span><span class="va">estimate</span><span class="op">-</span><span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="va">std.error</span>,p_value<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="va">test_stat</span>,df<span class="op">=</span><span class="fl">73</span>,lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   test_stat  p_value
##       &lt;dbl&gt;    &lt;dbl&gt;
## 1      7.92 1.97e-11</code></pre>
</div>
<div id="confidence-interval" class="section level4" number="28.3.1.2">
<h4>
<span class="header-section-number">28.3.1.2</span> Confidence interval<a class="anchor" aria-label="anchor" href="#confidence-interval"><i class="fas fa-link"></i></a>
</h4>
<p>We could calculate the confidence interval from the point estimate, standard error, and critical value but we will let <code>R</code> do it for us.</p>
<div class="sourceCode" id="cb901"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">star_mod</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 94.387896 197.652967
## carb         3.216643   5.377526</code></pre>
<p>This confidence interval does not contain the value 0. This suggests that a value of 0 is probably not feasible for <span class="math inline">\(\beta_1\)</span>.</p>
<p>In the end, we would declare that carbohydrate and calorie content of Starbucks’ menu items are linearly correlated. However, we DID NOT prove causation. We simply showed that the two variables are correlated.</p>
</div>
</div>
</div>
<div id="inference-on-predictions" class="section level2" number="28.4">
<h2>
<span class="header-section-number">28.4</span> Inference on Predictions<a class="anchor" aria-label="anchor" href="#inference-on-predictions"><i class="fas fa-link"></i></a>
</h2>
<p>Similarly, we can take advantage of the distribution of <span class="math inline">\(\hat Y_*\)</span> to build a confidence interval on <span class="math inline">\(Y_*\)</span> (the average value of <span class="math inline">\(Y\)</span> at some value <span class="math inline">\(x_*\)</span>):</p>
<p><span class="math display">\[
Y_*\in \left(\hat Y_* \pm t_{\alpha/2,n-2}\hat \sigma \sqrt{{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}} \right)
\]</span></p>
<p>There are a couple of things to point out about the above. First, note that the width of the confidence interval is dependent on how far <span class="math inline">\(x_*\)</span> is from the average value of <span class="math inline">\(x\)</span>. The further we are from the center of the data, the wider the interval will be.</p>
<p>Second, note that this in an interval on <span class="math inline">\(Y_*\)</span> the <strong><em>average</em></strong> value of <span class="math inline">\(Y\)</span> at <span class="math inline">\(x_*\)</span>. If we want to build an interval for a single observation of <span class="math inline">\(Y\)</span> (<span class="math inline">\(Y_{new}\)</span>), we will need to build a <em>prediction</em> interval, which is considerably wider than a confidence interval on <span class="math inline">\(Y_*\)</span>:</p>
<p><span class="math display">\[
Y_{new}\in \left(\hat Y_* \pm t_{\alpha/2,n-2}\hat \sigma \sqrt{1+{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}} \right)
\]</span></p>
<div id="starbucks-1" class="section level3" number="28.4.1">
<h3>
<span class="header-section-number">28.4.1</span> Starbucks<a class="anchor" aria-label="anchor" href="#starbucks-1"><i class="fas fa-link"></i></a>
</h3>
<p>Continuing with the <code>Starbucks</code> example. In plotting the data, we can have <code>R</code> plot the confidence and prediction bands, Figure <a href="LRINF.html#fig:ci271-fig">28.3</a>. We will observe the width of both of these intervals increase as we move away from the center of the data and also that prediction intervals are wider than the confidence interval.</p>
<div class="sourceCode" id="cb903"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">starbucks</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_point</span><span class="op">(</span><span class="va">calories</span><span class="op">~</span><span class="va">carb</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_labs</span><span class="op">(</span>x<span class="op">=</span><span class="st">"Carbohydrates"</span>,y<span class="op">=</span><span class="st">"Calories"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_lm</span><span class="op">(</span>stat<span class="op">=</span><span class="st">"lm"</span>,interval<span class="op">=</span><span class="st">"confidence"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_lm</span><span class="op">(</span>stat<span class="op">=</span><span class="st">"lm"</span>,interval<span class="op">=</span><span class="st">"prediction"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">gf_theme</span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:ci271-fig"></span>
<img src="28-Linear-Regression-Inference_files/figure-html/ci271-fig-1.png" alt="Confidence and predictions bands for linear regression model of calories and carbs in Starbucks' products." width="672"><p class="caption">
Figure 28.3: Confidence and predictions bands for linear regression model of calories and carbs in Starbucks’ products.
</p>
</div>
<p>We have not done diagnostics yet and it may be that using a linear regression model for this data may not be appropriate. But for the sake of learning we will continue. To find these confidence intervals we need a value for <code>carb</code> so let’s use 60 and 70.</p>
<p>We create a data frame with the new values of <code>carb</code> in it. Then we will use the <code>predict</code> function to find the confidence interval. Using the option <code>interval</code> set to <code>confidence</code> will return a confidence interval for the average calorie content for each value in the new data frame.</p>
<div class="sourceCode" id="cb904"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_carb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>carb<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">60</span>,<span class="fl">70</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">star_mod</span>, newdata <span class="op">=</span> <span class="va">new_carb</span>, interval <span class="op">=</span> <span class="st">'confidence'</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 379.7027 427.9883
## 2 446.8163 414.3687 479.2640</code></pre>
<p>Or using the <strong>broom</strong> package.</p>
<div class="sourceCode" id="cb906"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">star_mod</span>,newdata<span class="op">=</span><span class="va">new_carb</span>,interval<span class="op">=</span><span class="st">"confidence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##    carb .fitted .lower .upper
##   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1    60    404.   380.   428.
## 2    70    447.   414.   479.</code></pre>
<p>As an example, we are 95% confident that the average calories in a Starbucks’ menu item with 60 grams of carbs is between 379.7 and 428.0.</p>
<blockquote>
<p><strong>Exercise</strong>:
Give the 95% confidence interval of average calories for 70 grams of carbohydrates.</p>
</blockquote>
<p>We are 95% confident that the average calories in a Starbucks’ menu item with 70 grams carbs is between 414.4 and 479.3.</p>
<p>For the prediction interval, we simply need to change the option in <code>interval</code>:</p>
<div class="sourceCode" id="cb908"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_carb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>carb<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">60</span>,<span class="fl">70</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">star_mod</span>, newdata <span class="op">=</span> <span class="va">new_carb</span>, interval <span class="op">=</span> <span class="st">'prediction'</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 246.0862 561.6048
## 2 446.8163 287.5744 606.0582</code></pre>
<p>We are 95% confident the next Starbucks’ menu item that has 60 grams of carbs will have a calorie content between 246 and 561. Notice how prediction intervals are wider since they are intervals on individual observations and not an averages.</p>
<blockquote>
<p><strong>Exercise</strong>:
Give the 90% prediction interval of average calories for 70 grams of carbohydrates.</p>
</blockquote>
<p>We changed the confidence level. Since we are less confident, the interval will be narrower than the 95% prediction interval we just calculated.</p>
<div class="sourceCode" id="cb910"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">star_mod</span>, newdata <span class="op">=</span> <span class="va">new_carb</span>, level<span class="op">=</span><span class="fl">0.9</span>, interval <span class="op">=</span> <span class="st">'prediction'</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 271.9565 535.7345
## 2 446.8163 313.6879 579.9448</code></pre>
<p>We are 90% confident the next Starbucks’ menu item that has 70 grams of carbs will have a calorie content between 313.7 and 579.9.</p>
</div>
<div id="summary-2" class="section level3" number="28.4.2">
<h3>
<span class="header-section-number">28.4.2</span> Summary<a class="anchor" aria-label="anchor" href="#summary-2"><i class="fas fa-link"></i></a>
</h3>
<p>This chapter has introduced the process of inference for a simple linear regression model. We tested the slope estimate as well as generated confidence intervals for average and individual predicted values.</p>
</div>
</div>
<div id="homework-problems-27" class="section level2" number="28.5">
<h2>
<span class="header-section-number">28.5</span> Homework Problems<a class="anchor" aria-label="anchor" href="#homework-problems-27"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>In the chapter reading, we noticed that the 95% prediction interval was much wider than the 95% confidence interval. In words, explain why this is.</p></li>
<li><p>Beer and blood alcohol content</p></li>
</ol>
<p>Many people believe that gender, weight, drinking habits, and many other factors are much more important in predicting blood alcohol content (BAC) than simply considering the number of drinks a person consumed. Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer. These students were evenly divided between men and women, and they differed in weight and drinking habits. Thirty minutes later, a police officer measured their blood alcohol content (BAC) in grams of alcohol per deciliter of blood. The data is in the <code>bac.csv</code> file under the <code>data</code> folder.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a scatterplot for cans of beer and blood alcohol level.<br>
</li>
<li>Describe the relationship between the number of cans of beer and BAC.<br>
</li>
<li>Write the equation of the regression line. Interpret the slope and intercept in context.<br>
</li>
<li>Do the data provide strong evidence that drinking more cans of beer is associated with an increase in blood alcohol? State the null and alternative hypotheses, report the <span class="math inline">\(p\)</span>-value, and state your conclusion.<br>
</li>
<li>Build a 95% confidence interval for the slope and interpret it in the context of your hypothesis test from part d.<br>
</li>
<li>Suppose we visit a bar, ask people how many drinks they have had, and also take their BAC. Do you think the relationship between number of drinks and BAC would be as strong as the relationship found in the Ohio State study?<br>
</li>
<li>Predict the average BAC after two beers and build a 90% confidence interval around that prediction.<br>
</li>
<li>Repeat except build a 90% prediction interval and interpret.<br>
</li>
<li>Plot the data points with a regression line, confidence band, and prediction band.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Suppose I build a regression fitting a response variable to one predictor variable. I build a 95% confidence interval on <span class="math inline">\(\beta_1\)</span> and find that it contains 0, meaning that a slope of 0 is feasible. Does this mean that the response and the predictor are independent?</li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="LRBASICS.html"><span class="header-section-number">27</span> Linear Regression Basics</a></div>
<div class="next"><a href="LRDIAG.html"><span class="header-section-number">29</span> Regression Diagnostics</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#LRINF"><span class="header-section-number">28</span> Linear Regression Inference</a></li>
<li><a class="nav-link" href="#objectives-28"><span class="header-section-number">28.1</span> Objectives</a></li>
<li>
<a class="nav-link" href="#introduction-4"><span class="header-section-number">28.2</span> Introduction</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#regression"><span class="header-section-number">28.2.1</span> Regression</a></li>
<li><a class="nav-link" href="#review-of-assumptions"><span class="header-section-number">28.2.2</span> Review of assumptions</a></li>
<li><a class="nav-link" href="#distribution-of-our-estimators"><span class="header-section-number">28.2.3</span> Distribution of our estimators</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#inference"><span class="header-section-number">28.3</span> Inference</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#starbucks"><span class="header-section-number">28.3.1</span> Starbucks</a></li></ul>
</li>
<li>
<a class="nav-link" href="#inference-on-predictions"><span class="header-section-number">28.4</span> Inference on Predictions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#starbucks-1"><span class="header-section-number">28.4.1</span> Starbucks</a></li>
<li><a class="nav-link" href="#summary-2"><span class="header-section-number">28.4.2</span> Summary</a></li>
</ul>
</li>
<li><a class="nav-link" href="#homework-problems-27"><span class="header-section-number">28.5</span> Homework Problems</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/blob/master/28-Linear-Regression-Inference.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/DS-USAFA/Probability-and-Statistics-MASTER/edit/master/28-Linear-Regression-Inference.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Probability and Statistics - MASTER</strong>" was written by Matthew Davis, Brianna Hitt, Ken Horton, Kris Pruitt, Bradley Warner. It was last built on 2022-07-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
